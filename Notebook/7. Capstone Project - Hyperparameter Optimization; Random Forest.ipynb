{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227479fa",
   "metadata": {},
   "source": [
    "# 7. Capstone Project - Hyperparameter Optimization; Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca5492",
   "metadata": {},
   "source": [
    "#### Loading data and libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edf0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f56c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68315005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data set\n",
    "original_df = pd.read_csv(\"./capstone_clean_heart_disease_fe.csv\")\n",
    "\n",
    "# Train set : Under sampled data set and Over sampled data set\n",
    "under_sampled_df = pd.read_csv(\"./under_sampled_df_fe.csv\")\n",
    "over_sampled_df = pd.read_csv(\"./over_sampled_df_fe.csv\")\n",
    "# Test set : Under sampled data set and Over sampled data set\n",
    "test_sampled_df = pd.read_csv(\"./test_sampled_df_fe.csv\")\n",
    "               \n",
    "# Train set : SMOTE data set         \n",
    "smote_df = pd.read_csv(\"./smote_df.csv\")\n",
    "# Test set : SMOTE data set  \n",
    "test_smote_df = pd.read_csv(\"./test_smote_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d33cb",
   "metadata": {},
   "source": [
    "Split each dataset into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2828fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original data set into train and test set\n",
    "X = original_df.drop(columns=\"HeartDisease\")\n",
    "y = original_df[\"HeartDisease\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5f8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split other data set into X and y\n",
    "X_train_under = under_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_train_under = under_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_train_over = over_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_train_over = over_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_test_sampled = test_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_test_sampled = test_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_train_smote = smote_df.drop(columns=\"HeartDisease\")\n",
    "y_train_smote = smote_df[\"HeartDisease\"]\n",
    "\n",
    "X_test_smote = test_smote_df.drop(columns=\"HeartDisease\")\n",
    "y_test_smote = test_smote_df[\"HeartDisease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274afe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [X_train_original, X_train_under, X_train_over, X_train_smote]\n",
    "X_test = [X_test_original, X_test_sampled, X_test_sampled, X_test_smote]\n",
    "y_train = [y_train_original, y_train_under, y_train_over,y_train_smote]\n",
    "y_test = [y_test_original, y_test_sampled, y_test_sampled, y_test_smote]\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for index in range(4):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[index])\n",
    "    X_scaled_train = scaler.transform(X_train[index])\n",
    "    X_scaled_test = scaler.transform(X_test[index])\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_scaled_train,y_train[index])\n",
    "    \n",
    "    train_score.append(model.score(X_scaled_train,y_train[index])*100)\n",
    "    test_score.append(model.score(X_scaled_test,y_test[index])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf6e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Under Sampled</th>\n",
       "      <th>Over Sampled</th>\n",
       "      <th>SMOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train score</th>\n",
       "      <td>91.452915</td>\n",
       "      <td>75.787020</td>\n",
       "      <td>75.675365</td>\n",
       "      <td>80.968618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test score</th>\n",
       "      <td>91.389649</td>\n",
       "      <td>73.322747</td>\n",
       "      <td>73.284094</td>\n",
       "      <td>77.891185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original  Under Sampled  Over Sampled      SMOTE\n",
       "Train score  91.452915      75.787020     75.675365  80.968618\n",
       "Test score   91.389649      73.322747     73.284094  77.891185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_selection = pd.DataFrame((train_score, test_score), columns=[\"Original\", \"Under Sampled\", \"Over Sampled\", \"SMOTE\"], \n",
    "                                index=[\"Train score\", \"Test score\"])\n",
    "before_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5499a7",
   "metadata": {},
   "source": [
    "**Festure selection: RFE**  \n",
    "The columns that I'll use for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932af7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Original data final\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original)\n",
    "X_scaled_train = scaler.transform(X_train_original)\n",
    "X_scaled_test = scaler.transform(X_test_original)\n",
    "\n",
    "rfe_original = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=7)\n",
    "rfe_original.fit(X_scaled_train,y_train_original)\n",
    "    \n",
    "train_score_or_rfe = rfe_original.score(X_scaled_train,y_train_original)\n",
    "test_score_or_rfe = rfe_original.score(X_scaled_test,y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0c14db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176993</th>\n",
       "      <td>27.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267593</th>\n",
       "      <td>30.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175707</th>\n",
       "      <td>32.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317039</th>\n",
       "      <td>33.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262926</th>\n",
       "      <td>23.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>26.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>25.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>36.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>27.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>19.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BMI  Smoking  DiffWalking  Sex  AgeCategory  GenHealth  Asthma\n",
       "176993  27.12        1            0    1           35          3       0\n",
       "267593  30.23        0            0    0           18          2       0\n",
       "175707  32.55        0            0    1           60          3       0\n",
       "317039  33.07        0            0    0           55          3       0\n",
       "262926  23.06        0            0    1           30          4       0\n",
       "...       ...      ...          ...  ...          ...        ...     ...\n",
       "119879  26.62        0            0    0           40          4       0\n",
       "259178  25.04        0            0    1           25          4       0\n",
       "131932  36.05        0            0    0           18          1       0\n",
       "146867  27.44        0            0    0           40          3       0\n",
       "121958  19.77        1            0    1           55          4       0\n",
       "\n",
       "[223351 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_original.loc[:, rfe_original.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca83560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Under sampled data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under)\n",
    "X_scaled_train = scaler.transform(X_train_under)\n",
    "X_scaled_test = scaler.transform(X_test_sampled)\n",
    "   \n",
    "rfe_under = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=9)\n",
    "rfe_under.fit(X_scaled_train,y_train_under)\n",
    "    \n",
    "train_score_u_rfe = rfe_under.score(X_scaled_train,y_train_under)\n",
    "test_score_u_rfe = rfe_under.score(X_scaled_test,y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda056a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_Asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38180</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38181</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38182 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smoking  AlcoholDrinking  PhysicalHealth  DiffWalking  Sex  \\\n",
       "0            1                0             0.0            0    1   \n",
       "1            0                0             5.0            0    0   \n",
       "2            0                0             0.0            0    0   \n",
       "3            0                0             7.0            1    0   \n",
       "4            1                0             0.0            0    1   \n",
       "...        ...              ...             ...          ...  ...   \n",
       "38177        0                0             0.0            0    1   \n",
       "38178        0                0            30.0            1    0   \n",
       "38179        0                0             0.0            0    0   \n",
       "38180        1                0            15.0            0    1   \n",
       "38181        1                0             4.0            0    1   \n",
       "\n",
       "       AgeCategory  GenHealth  Asthma  Race_Asian  \n",
       "0               65          1       0           0  \n",
       "1               80          0       0           0  \n",
       "2               40          4       0           0  \n",
       "3               60          2       0           0  \n",
       "4               70          3       0           0  \n",
       "...            ...        ...     ...         ...  \n",
       "38177           75          3       0           0  \n",
       "38178           50          0       0           0  \n",
       "38179           75          2       0           0  \n",
       "38180           70          3       0           0  \n",
       "38181           50          2       0           0  \n",
       "\n",
       "[38182 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_under.loc[:, rfe_under.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd1752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Over sampled data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over)\n",
    "X_scaled_train = scaler.transform(X_train_over)\n",
    "X_scaled_test = scaler.transform(X_test_sampled)\n",
    "   \n",
    "rfe_over = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=11)\n",
    "rfe_over.fit(X_scaled_train,y_train_over)\n",
    "    \n",
    "train_score_ov_rfe = rfe_over.score(X_scaled_train,y_train_over)\n",
    "test_score_ov_rfe = rfe_over.score(X_scaled_test,y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f8a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_Asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408515</th>\n",
       "      <td>42.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408516</th>\n",
       "      <td>24.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408517</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408518</th>\n",
       "      <td>31.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408519</th>\n",
       "      <td>27.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408520 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BMI  Smoking  AlcoholDrinking  PhysicalHealth  MentalHealth  \\\n",
       "0       27.12        1                0             0.0           2.0   \n",
       "1       30.23        0                0             0.0           0.0   \n",
       "2       32.55        0                0             0.0           0.0   \n",
       "3       33.07        0                0             0.0           0.0   \n",
       "4       23.06        0                0             0.0           0.0   \n",
       "...       ...      ...              ...             ...           ...   \n",
       "408515  42.87        0                0            30.0           0.0   \n",
       "408516  24.41        0                0             0.0           0.0   \n",
       "408517  33.00        0                0             0.0           0.0   \n",
       "408518  31.32        1                0             3.0           2.0   \n",
       "408519  27.71        1                0            15.0          30.0   \n",
       "\n",
       "        DiffWalking  Sex  AgeCategory  GenHealth  Asthma  Race_Asian  \n",
       "0                 0    1           35          3       0           0  \n",
       "1                 0    0           18          2       0           0  \n",
       "2                 0    1           60          3       0           0  \n",
       "3                 0    0           55          3       0           0  \n",
       "4                 0    1           30          4       0           0  \n",
       "...             ...  ...          ...        ...     ...         ...  \n",
       "408515            1    0           60          2       0           0  \n",
       "408516            0    1           65          2       0           0  \n",
       "408517            0    1           60          1       0           0  \n",
       "408518            0    0           65          2       1           0  \n",
       "408519            1    1           75          1       0           0  \n",
       "\n",
       "[408520 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.loc[:, rfe_over.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759d5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : SMOTE data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote)\n",
    "X_scaled_train = scaler.transform(X_train_smote)\n",
    "X_scaled_test = scaler.transform(X_test_smote)\n",
    "    \n",
    "rfe_smote = RFE(estimator=LogisticRegression(max_iter=1500, random_state=42), n_features_to_select=10)\n",
    "rfe_smote.fit(X_scaled_train,y_train_smote)\n",
    "    \n",
    "train_score_s_rfe = rfe_smote.score(X_scaled_train,y_train_smote)\n",
    "test_score_s_rfe = rfe_smote.score(X_scaled_test,y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9744f360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_American Indian/Alaskan Native</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>Race_Black</th>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <th>Race_Other</th>\n",
       "      <th>Race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408515</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408516</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408517</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408518</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408519</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408520 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AlcoholDrinking  AgeCategory  GenHealth  Asthma  \\\n",
       "0                     0           35          3       0   \n",
       "1                     0           18          2       0   \n",
       "2                     0           60          3       0   \n",
       "3                     0           55          3       0   \n",
       "4                     0           30          4       0   \n",
       "...                 ...          ...        ...     ...   \n",
       "408515                0           80          1       0   \n",
       "408516                0           65          3       0   \n",
       "408517                0           70          2       0   \n",
       "408518                0           75          2       0   \n",
       "408519                0           75          3       0   \n",
       "\n",
       "        Race_American Indian/Alaskan Native  Race_Asian  Race_Black  \\\n",
       "0                                         0           0           0   \n",
       "1                                         0           0           0   \n",
       "2                                         0           0           0   \n",
       "3                                         0           0           0   \n",
       "4                                         0           0           1   \n",
       "...                                     ...         ...         ...   \n",
       "408515                                    0           0           0   \n",
       "408516                                    0           0           0   \n",
       "408517                                    0           0           0   \n",
       "408518                                    0           0           0   \n",
       "408519                                    0           0           0   \n",
       "\n",
       "        Race_Hispanic  Race_Other  Race_White  \n",
       "0                   0           0           1  \n",
       "1                   1           0           0  \n",
       "2                   0           0           1  \n",
       "3                   1           0           0  \n",
       "4                   0           0           0  \n",
       "...               ...         ...         ...  \n",
       "408515              0           0           1  \n",
       "408516              0           0           1  \n",
       "408517              0           0           0  \n",
       "408518              0           0           1  \n",
       "408519              0           0           1  \n",
       "\n",
       "[408520 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote.loc[:, rfe_smote.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd13ff",
   "metadata": {},
   "source": [
    "### Optimizing Hyperparameters: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e673f",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "071844ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c44132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_forest(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    RF_model = RandomForestClassifier()\n",
    "    RF_model.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = RF_model.score(X_train, y_train)\n",
    "    test_score = RF_model.score(X_test, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = RF_model.predict(X_test)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db821e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_forest_w_normalize(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "    RF_model = RandomForestClassifier()\n",
    "    RF_model.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    train_score = RF_model.score(X_scaled_train, y_train)\n",
    "    test_score = RF_model.score(X_scaled_test, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = RF_model.predict(X_scaled_test)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "930a046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_forest_w_pca_normalize(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "    my_PCA = PCA()\n",
    "    my_PCA.fit(X_scaled_train)\n",
    "\n",
    "    X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "    X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "    RF_model = RandomForestClassifier()\n",
    "    RF_model.fit(X_train_PCA, y_train)\n",
    "    \n",
    "    train_score = RF_model.score(X_train_PCA, y_train)\n",
    "    test_score = RF_model.score(X_test_PCA, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b72377",
   "metadata": {},
   "source": [
    "**Original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66da3e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.9625656477920403\n",
      "Test score: 0.8874971270972191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     87544\n",
      "           1       0.26      0.18      0.21      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.57      0.58     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "R_forest(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9be3071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.9625477387609637\n",
      "Test score: 0.8872672948747414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     87544\n",
      "           1       0.26      0.18      0.21      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.57      0.58     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "R_forest_w_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "37457807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.9626148976275011\n",
      "Test score: 0.8910804203840288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     87544\n",
      "           1       0.27      0.16      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.60      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "R_forest_w_pca_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357515a2",
   "metadata": {},
   "source": [
    "The test score became a little bit higher when the model is with PCA. However, the recall score for 1 became 0. Therefore, I'll do GridSearch with no PCA. Then I'll check if the model is better with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b23f46",
   "metadata": {},
   "source": [
    "**Under Sampled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57362689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.7071728547251416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.81     87544\n",
      "           1       0.19      0.77      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.74      0.56     95722\n",
      "weighted avg       0.90      0.71      0.77     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "R_forest(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df7316c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8011890419569431\n",
      "Test score: 0.7087816802824847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.19      0.77      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.74      0.56     95722\n",
      "weighted avg       0.90      0.71      0.77     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "R_forest_w_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26dc0ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.70601324669355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.81     87544\n",
      "           1       0.19      0.77      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.73      0.56     95722\n",
      "weighted avg       0.90      0.71      0.77     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "R_forest_w_pca_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22e34b",
   "metadata": {},
   "source": [
    "The both scores of test and recall for 1 became lower when the model is with PCA. Therefore, I'll do GridSearch with no PCA. Then I'll check if the model is better with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85c4b8",
   "metadata": {},
   "source": [
    "**Over Sampled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31e28994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.9753035347106629\n",
      "Test score: 0.8478719625582416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     87544\n",
      "           1       0.20      0.26      0.23      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.56      0.58      0.57     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "R_forest(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8c28e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.975301086850093\n",
      "Test score: 0.8483107331647897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     87544\n",
      "           1       0.20      0.26      0.23      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.57      0.58      0.57     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "R_forest_w_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ef05a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.9753084304318026\n",
      "Test score: 0.8531998913520403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     87544\n",
      "           1       0.21      0.25      0.23      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.57      0.58      0.57     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "R_forest_w_pca_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5322ff0",
   "metadata": {},
   "source": [
    "The test score increased when it's with PCA. However, the recall score for 1 became 0. Therefore, I'll do GridSearch with no PCA. Then I'll check if the model is better with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61983e2",
   "metadata": {},
   "source": [
    "**SMOTE data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaf94a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059654362087535\n",
      "Test score: 0.7534422598775621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "R_forest(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e0aba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.7534527067967657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "R_forest_w_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "382976c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059629883481837\n",
      "Test score: 0.7530870646246421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "R_forest_w_pca_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecced3",
   "metadata": {},
   "source": [
    "The test score became slightly lower when the model is with PCA. Also, the other evaluation scores became lower. Therefore, I'll do GridSearch with no PCA. Then I'll check if the model is better with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d68880",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1437ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def RF_gridsearch(num_tree, depth, split, leaf, X_train, y_train, X_test, y_test):\n",
    "    RF_param = {\n",
    "            'n_estimators': num_tree,\n",
    "            'max_depth': depth,\n",
    "            'min_samples_split': split,\n",
    "            'min_samples_leaf': leaf,\n",
    "            'max_features': [\"sqrt\", \"log2\", None],\n",
    "        #    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    # Create Randomized Search\n",
    "    clf = GridSearchCV(RandomForestClassifier(), RF_param, cv=5, scoring=\"f1\")\n",
    "    # Fit the model\n",
    "    clf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    # prediction and evaluation\n",
    "    y_pred = clf.predict(X_scaled_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    # Result\n",
    "    best_clf = clf.best_estimator_\n",
    "    print('Hyperparameter :\\n', best_clf)\n",
    "    print('Train score:\\n', best_clf.score(X_scaled_train, y_train))\n",
    "    print('Test score:\\n', best_clf.score(X_scaled_test, y_test))\n",
    "    print(f\"Best F1 Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde94f1",
   "metadata": {},
   "source": [
    "GridSearch takes too long time, so I'll use sample rows from each datasets. Thefore, I'll take samples and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1416fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take samples for GridSearch\n",
    "\n",
    "X_GS_original, X_rest_original, y_GS_original, y_rest_original = \\\n",
    "                train_test_split(X_train_original.loc[:, rfe_original.support_], y_train_original, train_size = 0.1, random_state=42)\n",
    "\n",
    "X_GS_under, X_rest_under, y_GS_under, y_rest_under = \\\n",
    "                train_test_split(X_train_under.loc[:, rfe_under.support_], y_train_under, train_size = 0.1, random_state=42)\n",
    "\n",
    "X_GS_over, X_rest_over, y_GS_over, y_rest_over = \\\n",
    "                train_test_split(X_train_over.loc[:, rfe_over.support_], y_train_over, train_size = 0.1, random_state=42)\n",
    "\n",
    "X_GS_smote, X_rest_smote, y_GS_smote, y_rest_smote = \\\n",
    "                train_test_split(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, train_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2c8eb",
   "metadata": {},
   "source": [
    "**Original data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70455a",
   "metadata": {},
   "source": [
    "train size = 0.1　　 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a05909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=30, n_estimators=500, random_state=42)\n",
      "Train score:\n",
      " 0.9883143049026192\n",
      "Test score:\n",
      " 0.8789724410271411\n",
      "Best F1 Score: 0.20666986235704993\n",
      "CPU times: total: 1h 14min 34s\n",
      "Wall time: 1h 15min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [10, 20, 30, None]\n",
    "split = [2, 5, 10]\n",
    "leaf =  [1, 2, 4]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_original, y_GS_original, \\\n",
    "        X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0f5b5",
   "metadata": {},
   "source": [
    "The parameter of max_depth is on the edge of the range, so max_depth could be higher. Therefore, I'll set the range higher and check the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8814730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=30, n_estimators=500, random_state=42)\n",
      "Train score:\n",
      " 0.9883143049026192\n",
      "Test score:\n",
      " 0.8789724410271411\n",
      "Best F1 Score: 0.20666986235704993\n",
      "CPU times: total: 1h 2min 48s\n",
      "Wall time: 1h 38min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [30, 40, 50, None]\n",
    "split = [2, 5, 10]\n",
    "leaf =  [1, 2, 4]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_original, y_GS_original, \\\n",
    "        X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba45b52",
   "metadata": {},
   "source": [
    "The parameter of max_depth is still 30. So, I'll use max_depth=30. Also, the parameter of n_estimators is 500, and it's on the edge of the range. I'll check some values for n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ec3418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAGwCAYAAACq12GxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNhElEQVR4nO3deXwU9eH/8dfm2E0IOSAhJCGBhAgknAkawRYBRStKaSHiF8UDUBQvxKMqWCtqEa22VqnVWsthSxV/ylGsijVU8aCRQwFBSDjCGTCAkIQQcn5+f6wZE5JAFpJsYN7Px2Meuzs789nPfJhl3/nMZ2YcxhiDiIiIiE35eLsCIiIiIt6kMCQiIiK2pjAkIiIitqYwJCIiIramMCQiIiK2pjAkIiIitqYwJCIiIrbm5+0KnA0qKyvJzc0lODgYh8Ph7eqIiIhIAxhjKCwsJCYmBh+f+vt/FIYaIDc3l7i4OG9XQ0RERE7D7t27iY2Nrfd9haEGCA4OBtyNGRIS4uXaiIiISEMUFBQQFxdn/Y7XR2GoAaoOjYWEhCgMiYiInGVONcRFA6hFRETE1hSGRERExNYUhkRERMTWFIZERETE1hSGRERExNYUhkRERMTWFIZERETE1hSGRERExNYUhkRERMTWFIZERETE1hSGRERExNYUhqRF2ZdfzIptB9mXX+ztqsg5SvuYNDXtY55pCe2lG7VKi/HGlzt5dPEGKg34OOChK7rx8z4x3q6WnEP+vS6XZz/M0j4mTUb7mGdObK+n03sxOq1js9fDYYwxzf6pZ5mCggJCQ0PJz8/XXesb6HhZBYePlXK4qMz9eKyUw8fKOFzkfn7kWBnfF5Vy5If5h46WUFRa4e1qi4iIF/k6HHw+5RKiQwMbpbyG/n6rZ8im9uUXk3OwiISIoJPudMYYikorrBBz+FgZR46V8n1RzedHjv0Qen6YX1zWOMHG38eBj4+jUcoSe6usNJRV1v7bT/uYNBbtY56pq70qjGHHwWONFoYaSmHIht5atYupC7+h0oADuKpXNJ3CW9Udbo6VUlZxep2Hvj4O2rTyp00rJ21aOQlr5U/bICdhrZzu+UHOH97zp7zSMOa1TKp/L3wdDj59uPH+QhB725dfzE+f+a/2MWky2sc8U197xUe0ava6KAzZzL78YqYs+Iaqfc8A732z75TrOf18aFst0Jwq3LQJchLs8sPhaPhfQ0+n9+KRhRuoMAZfh4MZ6T31H4g0mujQQO1j0qS0j3mmJbWXxgw1wLk0ZuitVbt5eMH6WvOv6NGe5OiQmuGmlfOHgONPoL+vR8HmdO3LL2bHwWPER7TSfyDSJLSPSVPTPuaZpmwvjRmSWvKPlTFzWXat+b4OB4//okeL+NJGhwa2iHrIuUv7mDQ17WOeaQntpesM2URFpeGe+V+z98hx2rTyp2osn7pxRUTE7tQzZBN/+E8Wy7MPEODvw7wJ/Wgb5FQ3roiICApDtvD+N/t4+ZNtAPzu6t70iAkFUAgSERFBh8nOeVn7C/nV2+sAuPXiBH6Z0sHLNRIREWlZFIbOYfnHyrjtH6s5VlrBT88L5+GhSd6ukoiISIujMHSOqhowvfPQMTqEBfKn6/ri56t/bhERkRPp1/Ec9fxHPw6Y/utN59M2yOntKomIiLRICkPnoA++2cefP649YFpERERqUxg6x2TtL+QBDZgWERFpMIWhc4gGTIuIiHhOYegcUVFpmPyWBkyLiIh4Sr+W54jnP8rikywNmBYREfGUwtA5QAOmRURETp/C0FlOA6ZFRETOjMLQWUwDpkVERM6cwtBZSgOmRUREGod+Pc9SGjAtIiLSOLwehubPn0/fvn0JDAykbdu2jBo1im3btp10nQMHDjB58mQSExMJCAggPj6eqVOnUlJSUmO5ZcuWcfnll9O+fXtcLhcxMTGMGjWKb775pik3qclpwLSIiEjjcRhjjLc+fNasWUyYMAGAhIQEDh06REFBAZGRkaxbt46oqKha65SUlNCnTx+ysrJwuVwkJSWRlZXF8ePHGTFiBIsWLQIgOzubXr16UVpaSps2bYiPj2fDhg2UlZXRrl079u3bh6+vb4PqWVBQQGhoKPn5+YSEhDReA5yG7O8KGfHnLzhWWsGEAQk8+vPuXq2PiIhIS9XQ32+v9QyVlpYyZcoUAK6++mq2b9/Opk2bCA4OJi8vjxkzZtS53rJly8jKygJgwYIFrF27liVLlgCwePFiVqxYAcDKlSspLS0F4IMPPuCrr75i6tSpABw6dIijR4/WW7eSkhIKCgpqTC1B/rEybvv7jwOmp1ypAdMiIiJnymthaNWqVRw8eBBwhyGAmJgY+vfvD8DSpUvrXK+ystJ67uPjU+MRICMjA4B+/frhdLrH0Vx11VX07duXp59+mtDQUGbOnEloaP2HlqqWq5ri4uJOdzMbTdWA6R0aMC0iItKovPZrunv3but5ZGSk9bx9+/YA7Nq1q871BgwYQHR0NADp6emkpqYyfPhw6/29e/cC0KVLFzIyMmjXrh3ff/89X3/9NWVlZcTGxtK9+8kPLU2dOpX8/Hxrql5Xb9GAaRERkabR4roWTjWEKSwsjIyMDIYPH05QUBA7duxgxIgRhIWFAeDv7w+4Q9HNN9/MgQMHeOuttzh69Cj33nsvGzduZNiwYezbt6/ez3C5XISEhNSYvEkDpkVERJqO18JQ9UNPeXl5tZ537Nix3nW7d+/OkiVLOHjwIIcPH+b3v/89R44cAaBbt24AvPzyy2zdupWQkBD+7//+j6CgIG666SYAiouL+eKLLxp7k5pE9nc/XmF6wgBdYVpERKSxeS0MpaWlER4eDrgHQgPk5uaSmZkJwNChQwFISkoiKSmJl156yVo3MzPTOo2+uLiYSZMmAe5eofT0dADy8/MBKCwsJDs7G4DVq1dbZQQFBTXZtjUWDZgWERFpel4LQ06n0zpjbMGCBXTu3Jnk5GQKCwuJiIiwzjTLysoiKyvLGmwNMH36dCIiIujduzfR0dEsXLgQgOeee44OHdw9JyNHjsThcGCMoW/fvvTu3Zvbb78dgE6dOjF48OBm3FrPacC0iIhI8/Dqr+ttt93GvHnzSElJITc3F4fDQXp6OitWrCAmJqbe9QYNGkRUVBRbtmyhvLycAQMGsGjRIiZPnmwtM2TIEN5//30uu+wyWrduTXZ2Nh07dmTChAl89tlnBAYGNscmnrY/fpRtDZh+9UYNmBYREWkqXr3o4tmiuS+6uHTDPm6f9xUAL16bonFCIiIip6HFX3RR6pb9XSH3/z8NmBYREWkuCkMtSPUB0z9J1IBpERGR5qAw1EKcOGD6pTEaMC0iItIc9GvbQmjAtIiIiHcoDLUASzfs46WPtwLuK0z37KArTIuIiDQXP29XwM725Rfz2ZaDPPavDYAGTIuIiHiDwpCXvLVqF1MXfkPlDxc2SGwXpAHTIiIiXqDDZF6wL7+4RhACyDlYxIGjJd6rlIiIiE0pDHlBzsGiGkEIoNLAjoPHvFMhERERG1MY8oKEiCB8HDXn+TocxEe08k6FREREbExhyAuiQwN5Or0Xvg53IvJ1OJiR3pPo0JZ9vzQREZFzkQZQe8notI4M7NqOHQePER/RSkFIRETESxSGvCg6NFAhSERExMt0mExERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERszethaP78+fTt25fAwEDatm3LqFGj2LZt20nXOXDgAJMnTyYxMZGAgADi4+OZOnUqJSUltZZdvHgxAwcOJDg4mMDAQLp06cIzzzzTVJsjIiIiZxmHMcZ468NnzZrFhAkTAEhISODQoUMUFBQQGRnJunXriIqKqrVOSUkJffr0ISsrC5fLRVJSEllZWRw/fpwRI0awaNEia9k//OEP/OpXvwIgKiqK6Oho8vLySE5O5qOPPmpwPQsKCggNDSU/P5+QkJAz3GoRERFpDg39/fZaz1BpaSlTpkwB4Oqrr2b79u1s2rSJ4OBg8vLymDFjRp3rLVu2jKysLAAWLFjA2rVrWbJkCeDuBVqxYgUAu3fvtsqfOXMmubm5fPXVV+zZs4eFCxc29eaJiIjIWcJrYWjVqlUcPHgQcIchgJiYGPr37w/A0qVL61yvsrLSeu7j41PjESAjIwOAhQsXUl5eTlBQEJmZmURERBAdHc2NN95IUVHRSetWUlJCQUFBjUlERETOTV4LQ7t377aeR0ZGWs/bt28PwK5du+pcb8CAAURHRwOQnp5Oamoqw4cPt97fu3cvgNV7VFRUxNtvv010dDSHDh1i3rx5XHXVVZSVldVbt6effprQ0FBriouLO82tFBERkZbO6wOoT3SqIUxhYWFkZGQwfPhwgoKC2LFjByNGjCAsLAwAf39/AMrLy611Zs+ezYYNG5g1axYAX3/9NV988UW9nzF16lTy8/OtqXpwExERkXOLn7c+uHpvS15eXq3nHTt2rHfd7t27W+OEAHJzc3nzzTcB6NatGwAdOnSw3k9LSwPgwgsvtObt2LGj3vJdLhcul6shmyEiIiJnOa/1DKWlpREeHg64B0KDO9RkZmYCMHToUACSkpJISkripZdestbNzMy0TqMvLi5m0qRJgLtXKD09HYDLLrvMWn716tU1HgG6dOnSJNslIiIiZxevhSGn02mdMbZgwQI6d+5McnIyhYWFREREWGeCZWVlkZWVZQ22Bpg+fToRERH07t2b6Oho6+yw5557zuoR+ulPf8ovf/lLAMaPH0+vXr0YP348AEOGDOGnP/1ps22riIiItFxeHTN02223MW/ePFJSUsjNzcXhcJCens6KFSuIiYmpd71BgwYRFRXFli1bKC8vZ8CAASxatIjJkyfXWG7+/Pk8/PDD1rIJCQn85je/4d13323qTRMREZGzhFcvuni20EUXRUREzj4t/qKLIiIiIi2BwpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsdh6P/9v/9HaWlpU9RFREREpNl5HIauvfZaoqOjuf3221mxYkVT1ElERESk2Xgchnx9fTl8+DCvvfYaF198MV27dmX69Ons3LmzKeonIiIi0qQ8DkN5eXnMmTOHq666CqfTydatW5k2bRqJiYkMHjyY119/nbKysqaoq4iIiEijcxhjzOmufPToUV5//XWmTJlCUVERDocDgA4dOrBw4UIuuOCCRquoNxUUFBAaGkp+fj4hISHero6IiIg0QEN/v0/7bLL//Oc/TJgwgQcffJBjx44B0KpVK7p168aePXuYOHHi6RYtIiIi0mz8PF3hscce4/XXX2fPnj1UdSp1796dO+64g5tuuong4GAuvvhivvzyy0avrIiIiEhj8zgMTZ8+HQB/f3/S09O58847ufjii2ssc8EFF7Bnz57GqaGIiIhIE/J4zFB8fDwTJ07klltuITIysqnq1aJozJCIiMjZp6G/3x73DOXk5FgDpUVERJpaZWWlLvYrdfL398fX1/eMy/E4DD388MNkZGQwZ84c+vTpA8D69esZN24cl112Gc8++6xH5c2fP59nn32WTZs2ERgYyKWXXsrvfvc7EhMT613nwIEDTJ8+nX//+9/s3buXqKgorrvuOh5//HFcLlet5b/++mv69+9vfZk2bdpEUlKSR/UUEZHmV1paSk5ODpWVld6uirRQYWFhREVFnVFHjceHyeLi4qisrGTv3r015sfGxuJwONi9e3eDy5o1axYTJkwAICEhgUOHDlFQUEBkZCTr1q0jKiqq1jolJSX06dOHrKwsXC4XSUlJZGVlcfz4cUaMGMGiRYtqLF9cXEzfvn3ZvHmzNc/TMKTDZCIizc8Yw65duygrKyMmJgYfH91OU35kjOHYsWPk5eURFhZGdHR0rWWa7DBZXl4eXbp0qTU/LCyMrVu3Nric0tJSpkyZAsDVV1/NO++8Q25uLklJSeTl5TFjxgxmzpxZa71ly5aRlZUFwIIFCxg2bBgfffQRP/vZz1i8eDErVqzgJz/5ibX8/fffz+bNm7nmmmt4++23G1S3kpISSkpKrNcFBQUN3i4REWkc5eXlHDt2jJiYGFq1auXt6kgLFBgYCLizSWRk5GkfMvM4Zrdt25bs7Owap86vXLmSrKws2rRp0+ByVq1axcGDBwF3GAKIiYmhf//+ACxdurTO9ap3lVb9lVD9r4WMjAzr+bvvvstf/vIXJk2axFVXXdXguj399NOEhoZaU1xcXIPXFRGRxlFRUQGA0+n0ck2kJasKymdy9wuPw9All1xCeXk5gwYN4oorruCKK65g4MCBVFZWMmTIkAaXU/1wWvWz0tq3bw/Arl276lxvwIABVldYeno6qampDB8+3Hq/6vDd/v37ueWWW+jVq5fH45imTp1Kfn6+NXly6E9ERBqXTtqRk2mM/cPjMPTkk08SGhpKaWkpGRkZZGRkUFpaSlhYGE888cQZV+hUQ5jCwsLIyMhg+PDhBAUFsWPHDkaMGEFYWBjgHlkOMHHiRAoLC3njjTcICAjwqA4ul4uQkJAak4iIiJybPA5D5513HqtXr2bcuHEkJyeTnJzM+PHjWbly5UnPADtR9UNPeXl5tZ537Nix3nW7d+/OkiVLOHjwIIcPH+b3v/89R44cAaBbt24ArFu3jtLSUvr370/r1q25/fbbrfXPP/98Hn744QbXVUREpKWYO3cuDodDPWaN6LSG5icmJjJ79mw2bNjAhg0bmDVrlkdBCCAtLY3w8HDAPRAaIDc3l8zMTACGDh0KQFJSEklJSbz00kvWupmZmdYA5+LiYiZNmgT8eFXsKpWVlRQVFVFUVFRjQPSxY8dqvBYREWkM8fHxVlCpb3r88cfP6DPatWtHv3796NevX6PUOT8/n4ceeoguXboQGBhImzZtSE5OZvTo0ba5m4THZ5OB+0ywL774gtzcXGuAW5WbbrqpQWU4nU5mzJjBxIkTWbBgAZ07d+bQoUMUFhYSERFhnWlWdeZY1WBrcN8SZPny5SQkJLBr1y7y8/MBeO655+jQoQMAO3bsqPF5c+fOZfz48YCuMyQiIk0jNTXVuizMnj17rHGsKSkp1nXwYmNja61XWlra4IHiw4YNY9iwYY1UY/fv9pIlS3A4HCQnJwPu39DNmzfz4IMP1lnfxubJ9jcJ46Hs7GzTsWNH4+PjU2vy9fX1tDgzb948k5KSYlwulwkNDTXp6ekmOzvbeh8wgJk2bZo179lnnzXnnXeeCQgIMEFBQWbAgAFm0aJFJ/2cOXPmWGVt2rTJozrm5+cbwOTn53u0noiInL7i4mLz7bffmuLi4jMuK/fIMfPF1gMm98ixRqhZw0ybNs363cnJybHmDxo0yADmhhtuML/61a9Mu3btTHx8vDHGmOeff9706dPHtGnTxvj5+ZmIiAgzcuRIk5WVZa1f/ffsxDJvvPFG89hjj5moqCgTFhZmrr/+elNQUFBvHY8ePWp8fHwMYGbPnm3NLysrMx9++KHZt2+fNa+kpMRMnz7dJCUlWb/ZAwcONLt377aWmT17tunbt68JCAgwrVq1Mj/5yU/M4sWLrfdzcnKsur/22mvm0ksvNS6Xy/qN37t3rxk/fryJjo42/v7+JiEhwTz55JOmrKys3m042X7S0N9vj8NQenq6cTgcdU4+Pj6eFndWUBgSEWl+J/7IVVZWmqKSMo+nv6/IMQlT/m06PfxvkzDl3+bvK3I8LqOystLj+p8qDDmdTuPv72969uxpevfubYwx5pe//KUJCgoyycnJpmfPnsbX19cAJjY21mqHk4Uhf39/ExwcbBISEqxlHnnkkXrrePToUeNwOAxghg0bZv7zn/+Y77//vs5lf/7zn1tlRkdHm6SkJOPr62u+/vprY4wxv/3tb633O3bsaKKioqzX//jHP4wxNcOQ0+k04eHhpnv37ubJJ580Bw8eNHFxcQYwwcHBpnfv3sbPz88AZvz48fVuQ2OEIY8Pk3322Wf4+fnxwQcfcPnll5OamspDDz3EpEmTmD9/vqfFiYiINEhxWQXdH/vwjMqoNPCbf23kN//a6NF63z55Ba2cpzWy5KRWrVpFnz59rCEnM2bM4O2337bOjM7IyODyyy9nz549fPHFF6e8hE1AQACbNm0iOjqaCy+8kDVr1rBs2TKeeuqpOpcPCgripptu4vXXX+e9997jvffew+Fw0KdPH2655RbuuOMOfH19+fTTT/n3v/8NwN13382LL76Ij48PO3fuJDg4mKKiImbMmAHAyJEjeeeddygrK2PgwIGsXLmSRx99lBtuuKHGZ1900UUsXbqUgIAAKioqmD59Ort376Z9+/Z88803tGvXjn/961+MGDGCuXPn8sgjj3DeeeedUXvXx+MB1EeOHCE5OZkhQ4bgcDjw9/dn9OjRREVFWQ0hIiIiJ3fJJZdY9/isunLyzp07ueSSSwgJCcHHx4fLL7/cWj43N/eUZV566aV06NABHx8fa2zsd999d9J1Zs+ezezZs7nssssIDAzEGMPatWuZNGkSv/3tbwFqXGh5ypQp1sWOO3XqRNu2bdm4cSPFxcUAXHvttfj4+OByuayLKu/cuZMDBw7U+Nzbb7/duvSNr68vK1eutOobGRmJw+FgxIgRgPuyO9Xr0Ng8jrnBwcHWVaBbt27N5s2b+fLLL9m1axfbtm1r9AqKiIgABPr78u2TV3i0zv7841z2/HIqq13CzscBGfcPIiq04degC/Q/8zujn6jqIsNVtm/fzogRIygtLSU4OJjzzz+f8vJy1q5dC1DrhKW6VF1zD8DPz/0Tb05x/T4fHx/Gjx/P+PHjKS8v5/PPP+eGG25g7969LF68+IzPfqvPidtfJTg4mO7du9ea35S3ZPG4ZyguLo6dO3dSUVFBr169KCws5Cc/+QmFhYV13iRNRESkMTgcDlo5/TyaOrdrzdPpvfD94Zo8vg4HT6f3onO71h6V0xTX9DmxzK+//prS0lIAPvzwQ1atWtXk18QrLS3l4YcfJjs7G3AHqIsvvtg6Mzs0NBSgxmn8zz33nBWwdu/ezffff0+PHj2s+4S99dZbVFZWUlJSwsKFCwF3D1K7du1qfPaJ25+WlmbVYf78+WRmZpKZmclHH33EnXfeyciRIxt78y0eh6GxY8cyZMgQtmzZwq9//Wv8/f0xxuDj49Nk6VFEROR0jU7ryOdTLuHNW/vz+ZRLGJ1W/0V9valHjx7W4bKhQ4fSq1cv6zp6TaWyspJnn32Wbt260aFDBy644AJiYmKsQ1ZjxowBYODAgfz85z8H4MUXX6RDhw50796dzp07s2vXLoKCgnjkkUcAWLhwIQkJCcTHx1uHtqZPn37Kutx111106NCBw4cP061bN1JSUkhMTCQ8PJyxY8c2xeZbPA5D9913H4sWLSIpKYkrr7ySTZs28c4777Bhw4Zag6NERERagujQQC5KDCc6NNDbValXUlISs2fPJiEhgdLSUiIiInjzzTeb9DOdTifPPvssV1xxBb6+vmzcuJGCggL69OnDiy++yMSJE61lFyxYwPTp00lKSuLQoUPs3buXiy66iIiICAAeffRRZs2aRd++fcnLyyM/P5+LLrqIxYsXNygftGvXjszMTMaPH094eLg1Duniiy/mj3/8Y5O1AYDDnOpgYjVlZWUkJSURGhrKmjVrbHMp8IKCAkJDQ8nPz9d9ykREmsnx48fJyckhISHB43tMin2cbD9p6O+3Rz1D/v7+FBYWUlFRYZsgJCIiIuc2jw+TjRs3jqysLDZs2NAU9RERERFpVh6fWr9//37APer7kksuoX379lYvkcPhYNasWY1bQxEREZEm5HEYmjdvHg6HA2MMS5cutYKQMUZhSERERM46HoehgQMHaryQiIiInDM8DkOffPJJE1RDRERExDs8HkAtIiIici7xuGeo6uqYdXE4HJSXl59RhURERESak8dhyINrNIqIiIi0eB6HoTlz5tR4nZ+fz6JFi/j8888bdO8RERERkZbktG7UWn265557yMjIoGvXrqxdu7YJqigiInJ2iI+Px+FwnHRqjJua79ixwyqvISc2lZaWMmPGDLp3705QUBAhISGcd955jBw5knXr1p1xfc52HvcM1cXhcODj48N7773XGMWJiIiclVJTU4mKigJgz5497N27F4CUlBRcLhcAsbGxzV6vBx98kJkzZwLQpUsXAgIC2LFjB4sXL+b666+nT58+TV6H0tJSnE5nk3/O6fC4Z+jSSy+tMQ0aNIj4+Hi+/fZbQkNDm6KOIiIiZyZ/L+R86n5sQosWLSIzM5PMzEwmTJhQ5/xrrrmGyZMn06lTJ5xOJ7Gxsdx///0cO3bMWj4rK4tf/OIXREZG4nK5iI2N5corr2TlypXMnTuXhIQEa9lLLrkEh8PB4MGD663XW2+9BcBjjz1GdnY269evJz8/n88//7xGEDLG8PLLL5OamkpgYCDBwcFceOGFNY78LFmyhAEDBtC6dWsCAgJITU2tdcHlql6rZ599lvT0dFq3bs1tt90GuIfXnGr7m9tpXWeo6grUJ7rzzjsbpVIiIiK1GANlp/GDufYN+OAhMJXg8IErn4WUMZ6V4d8KGuGCw6WlpQwePJi1a9cSEBBAcnIy2dnZ/PGPf2TdunVkZGTgcDi47rrr+Prrr2nTpg09evRg//79LF26lNGjR9OuXTtSUlKsgJKcnExISAjdu3ev93MrKysB+M9//kNaWhppaWm0b9+en/70pzWWu+eee3jppZcACA8PJyoqinXr1rFjxw5SUlKYN28eN954IwDt27cnICCAtWvXMmHCBPbv38+vf/3rGuX95je/ISAggISEBJxOZ4O3v7k5jIenh40bN65GRR0OB5GRkQwZMoTLL7+80SvYEhQUFBAaGkp+fj4hISHero6IiC0cP36cnJwcEhISCAgIgNIimBHjnco8kgvOII9Wefzxx3niiScAyMnJIT4+ntdff51x48bhdDrZsGEDXbp0Yd26daSkpACQkZHBkCFDCA4O5ujRo3z++edWYMnJycHhcBAfH8+OHTus3qGPP/74pL1CJ9alSrdu3bj++ut58MEHrcNmnTt3xhjDyJEjmT9/Pk6nkwMHDlBSUkJsbCydOnVi165d9OvXj+XLl+N0Orn66qtZtGgRgYGBHDx4kFatWlk5ISkpiRUrVtCmTRsqKiqYN29eg7bfE7X2k2oa+vvtcc/Q3LlzPV1FREREgJUrVwLuHqKuXbvWej8zM5MhQ4YwfPhw3nzzTS655BISExPp3r07l112GTfffPNpfe7jjz9Onz59mDNnDsuXL6egoICsrCwee+wxtm3bxty5c1m1apV11OeBBx6wxve0a9cOgLy8PHbt2gVAenq6NQbq2muvZdGiRRQXF7Nx40bS0tKszx07dixt2rQB3NcpbOj2NzePw9D69evZsWMHF1xwATEx7oS+d+9e1qxZQ3x8PL179270SoqIiODfyt1D44mCXPjzhe5DZFUcvnDXlxDiQS+TfyvPPvcUnE4nqampteZXBYe///3v/OIXv+CTTz7h22+/5f3332fhwoVs2LCBP//5z6f1mSNHjmTkyJFUVlayZs0abrnlFr755hsWL158JptyUu3bt69z/qm2v7l5HIZuvfVW1q9fz549e6x5gYGBjB49mpSUFP73v/81agVFREQA95gdDw9VEdEFhr8I794LpsIdhIa/4J7vBVW9JhUVFbz88sv07dsXcB/qee+996xekc8++4yRI0dy7bXXAvDMM88wdepUPv30UwBatfoxnBUVFZ3ycx999FFGjRpFSkoKPj4+pKWl0bVrV7755hvr5Ke0tDRrTPALL7xAWloaTqeTQ4cOUVxcTGxsLB07dmTXrl0sXLiQyZMn43Q6mT9/PuDOAj169KjxuSeO/2no9jc746Hg4GDTq1evWvN79eplgoODPS3urJCfn28Ak5+f7+2qiIjYRnFxsfn2229NcXHxmRd2ZI8x2z91PzaTadOmGcAAJicnxxhjzPHjx03v3r0NYHx8fEyPHj1M165djcvlqrFchw4dTGBgoOnatatJSUkx/v7+BjBjxowxxhhTWVlpwsPDDWDatGljLrzwQjNz5sx669K+fXsDmIiICNO3b18TGxtr1W3KlCnWcnfffbc1PyIiwvTs2dO4XC6zaNEiY4wx//jHP6z327dvbzp16mS9nj59ulVO1bw5c+bUqEdDt98TJ9tPGvr77fGp9eXl5ezfv7/GPcjKysrYv38/FRUVp5vJREREmk5oB0i42P3oRS6Xi+XLl3PPPfcQFxdHdnY2hw8f5oILLuCpp56yDiuNHz+eHj16cPDgQb799luioqK47bbbrDO9HA4Hr732Gueddx4FBQWsXLmSnTt31vu506dP55e//CXBwcFs3ryZvLw8unXrxrRp0/jtb39rLTdz5kz+/Oc/k5KSwtGjR8nJyaF3797Ex8cDcMMNN/Cvf/2Ln/70pxQWFrJ//35SUlL429/+VutMsjPZ/ubm8dlkffv2Zd26daSnp3P//fcD8MILL/D222+TmprKmjVrmqSi3qSzyUREmt/JzhISqeKVs8kmTJjA3XffzcKFC1m4cKE13+FwcOutt3panIiIiIhXeXyY7M477+Suu+4C3FeqrOpYuuuuu7j99tsbt3YiIiIiTey07k32pz/9iV/96lesWrUKcI8O79SpU6NWTERERKQ5eByGSkpKKCkpoUOHDlYAKi8vp6CgAJfLZV2ESURERORs4PFhshEjRtC2bVu2bNlizdu6dSvh4eGMHDmyUSsnIiLi4Xk+YjONsX94HIZWrVpFYmIiycnJ1rykpCQ6d+5sHTYTERE5U76+voD71g0i9am6272/v/9pl+HxYbLCwsI6T08rKyujsLDwtCsiIiJSnZ+fH61ateLAgQP4+/vj4+Px3+9yDjPGcOzYMfLy8ggLC7PC8+nwOAzFxcWRk5PD888/z3333YfD4eCFF16w7nYrIiLSGBwOB9HR0eTk5Jz0goJib2FhYURFRZ1RGR6HoREjRvD888/z4IMP8uijjwLuQdUOh4P09PQzqoyIiEh1TqeTLl266FCZ1Mnf3/+MeoSqeHwF6qNHjzJo0CC+/vrrGvP79u3LJ598QuvWrc+4Ui2NrkAtIiJy9mmyK1C3bt2azMxM3nzzTVauXAlA//79GThwIDNnzuSRRx45/VqLiIiINDOPe4aqO378OAsWLOD111/n448/xhhT4wau5wr1DImIiJx9mqxnCGDFihXMnTuXt99+m4KCAsA9qtvhcJxebUVERES8pMFhaO/evbz++uu8/vrrbN26FfjxQkdVZ5RpALWIiIicbRp8mMzPz6/GjVl79+7NjTfeyOOPP86xY8eoqKho0op6kw6TiYiInH0a+vvd4CtYVVZWAu6bsq5du5a1a9fywAMP4Od3WkfaRERERFoEjy/nuXr1aq688koeeugh1q9f3xR1EhEREWk2DQ5Ds2fPZuDAgQDs27ePP/zhD6SmppKfnw/A5s2bm6aGIiIiIk2owWFo3LhxfPzxx2zbto3HHnuM+Pj4GneK7dGjB927d2+SSoqIiIg0lTO6ztDy5cuZM2cOCxYsoKioCIfDcU4OpNYAahERkbNPow+grsugQYOYO3cu+/fvr3EYTURERORscUY9Q3ahniEREZGzT7P0DDWG+fPn07dvXwIDA2nbti2jRo1i27ZtJ13nwIEDTJ48mcTERAICAoiPj2fq1KmUlJRYy2zcuJFx48aRlJRESEgIoaGhnH/++cyaNaupN0lERETOIl7tGZo1axYTJkwAICEhgUOHDlFQUEBkZCTr1q0jKiqq1jolJSX06dOHrKwsXC4XSUlJZGVlcfz4cUaMGMGiRYsAmDt3LuPHj6dNmzZ07NiR7OxsiouLAfjd737HQw891OB6qmdIRETk7NPie4ZKS0uZMmUKAFdffTXbt29n06ZNBAcHk5eXx4wZM+pcb9myZWRlZQGwYMEC1q5dy5IlSwBYvHgxK1asAKBjx468/fbbHDhwgLVr17Jp0yZCQ0MB+Oc//9nUmyciIiJnCa+FoVWrVnHw4EHAHYYAYmJi6N+/PwBLly6tc72qK2ED+Pj41HgEyMjIAODSSy9l1KhR+Pr6AtCpUyc6duwIgMvlOmndSkpKKCgoqDGJiIjIuclrYWj37t3W88jISOt5+/btAdi1a1ed6w0YMIDo6GgA0tPTSU1NZfjw4db7e/furXO9Tz/9lI0bNwJw6623nrRuTz/9NKGhodYUFxfXgC0SERGRs5HXB1Cf6FRDmMLCwsjIyGD48OEEBQWxY8cORowYQVhYGAD+/v611nn//fcZNmwYlZWV3HPPPacMQ1OnTiU/P9+aqgc3ERERObd47S6r1Xtb8vLyaj2vOqRVl+7du1vjhAByc3N58803AejWrVuNZV955RUmTZpERUUFTz75JL/5zW9OWTeXy3XKQ2kiIiJybvBaz1BaWhrh4eGAeyA0uENNZmYmAEOHDgUgKSmJpKQkXnrpJWvdzMxM6zT64uJiJk2aBLh7hdLT0wF3D9NDDz3EnXfeia+vL/PmzWtQEBIRERF78eqp9X/961+ZOHEiUPPU+oiICNatW0dMTAwOhwOAadOm8fjjjwPw85//nOXLl5OQkMCuXbusm8W+8MILTJ48GYA333yTMWPGABAREUFiYmKNz64KXQ2hU+tFRETOPg39/fbaYTKA2267jaCgIH7/+9+zadMmAgICSE9P55lnniEmJqbe9QYNGkRWVhZbtmzB19eXAQMG8MADDzBixAhrmeoXYDx48KB15pqIiIhIdbodRwOoZ0hEROTs0+IvuigiIiLSEigMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK15PQzNnz+fvn37EhgYSNu2bRk1ahTbtm076ToHDhxg8uTJJCYmEhAQQHx8PFOnTqWkpKTGct999x0333wzkZGRuFwuunfvzksvvdSUmyMiIiJnGYcxxnjrw2fNmsWECRMASEhI4NChQxQUFBAZGcm6deuIioqqtU5JSQl9+vQhKysLl8tFUlISWVlZHD9+nBEjRrBo0SIAioqKOP/888nKyiIwMJDY2Fi2bNkCwG9+8xuefPLJBtezoKCA0NBQ8vPzCQkJaYQtFxERkabW0N9vr/UMlZaWMmXKFACuvvpqtm/fzqZNmwgODiYvL48ZM2bUud6yZcvIysoCYMGCBaxdu5YlS5YAsHjxYlasWAHAq6++SlZWFg6Hg8zMTLKzs7n//vsBeOaZZ/juu++aehNFRETkLOC1MLRq1SoOHjwIuMMQQExMDP379wdg6dKlda5XWVlpPffx8anxCJCRkQHABx98AECXLl3o3bt3jc8pKytj2bJl9datpKSEgoKCGpOIiIicm7wWhnbv3m09j4yMtJ63b98egF27dtW53oABA4iOjgYgPT2d1NRUhg8fbr2/d+/eGuXXVfbJygd4+umnCQ0Ntaa4uLgGb5eIiIicXbw+gPpEpxrCFBYWRkZGBsOHDycoKIgdO3YwYsQIwsLCAPD39z/tsqtMnTqV/Px8a6oe3EREROTc4uetD67e25KXl1freceOHetdt3v37tY4IYDc3FzefPNNALp162aVn5WVVWfZpyrf5XLhcrkauikiIiJyFvNaz1BaWhrh4eGAeyA0uENNZmYmAEOHDgUgKSmJpKSkGqfEZ2ZmWqfRFxcXM2nSJMDdK5Senl5j/S1btrB+/foan+Pv78+QIUOadPtERETk7OC1MOR0Oq0zxhYsWEDnzp1JTk6msLCQiIgI60yzrKwssrKyrMHWANOnTyciIoLevXsTHR3NwoULAXjuuefo0KEDABMnTqRLly4YY+jfvz/dunXj+eefB+DBBx+sMX5IRERE7MurY4Zuu+025s2bR0pKCrm5uTgcDtLT01mxYgUxMTH1rjdo0CCioqLYsmUL5eXlDBgwgEWLFjF58mRrmdatW7N8+XLGjh1LUFAQOTk5JCUl8cILL/DUU081x+aJiIjIWcCrF108W+iiiyIiImefFn/RRREREZGWQGFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hSERERGxNYUhERERsTWFIREREbE1hyJvy90LOp+5HERER8Qo/b1fAtr76O7w7GUwlOHxg+IvQ9yZv10pERMR21DPkDfl7fwxC4H58d7J6iERERLxAYcgbvt/2YxCqYiph0W2w/ROorKxzNREREWl8OkzmDW0T3YfGTgxEOz53T20S4PyxkHIDtG7nnTqKiIjYhHqGvCG0g3uMkMPX/drhC4MehrQJ4AqBwzmQ8Tg8nwz/byxs+1i9RSIiIk3EYYwx3q5ES1dQUEBoaCj5+fmEhIQ0XsH5e+H77dC2szsgAZQWwcZFsGYu7Fn147Jt4qHvWEi5HoLbN14dREREzlEN/f1WGGqAJgtDp7J/A3z1Oqx7C0ry3fN8/KDbVXD+OOh8Cfioc09ERKQuCkONyGthqErpMfh2sbu3aPeXP84P6+Q+HT/1BgiOav56iYiItGAKQ43I62Gouu++/aG36E04/kNvkcMXul0J54+HxEvVWyQiIoLCUKNqUWGoSukx+PZfP/QWZf44P7QjnH+T+0y0kGivVU9ERMTbFIYaUYsMQ9XlbYI1Vb1FR9zzrN6icT/0Fvl6s4YiIiLNTmGoEbX4MFSlrBi+XeLuLdq14sf5oXE/ji0KiXHPy9/rvvhj28Qfz2QTERE5hzT099vrg0vmz59P3759CQwMpG3btowaNYpt27addJ28vDzuuOMO4uPjCQgIoE2bNlx44YXMnj27xnJfffUVI0aMICYmBpfLRfv27bnyyiv57LPPmnKTvMc/EPqMhps/gLtWQv+7ILAN5O+Gj5+CP/aAN6+DDx6GF3rC68Pdj1/93ds1FxER8Rqv9gzNmjWLCRMmAJCQkMChQ4coKCggMjKSdevWERVV9xlSgwcPZvny5fj6+tKzZ0/27dtHXl4eAEuWLGH48OEcOXKEhIQEjhw5QuvWrenSpQtZWVkcO3YMl8vF7t27adeuYVd3Pmt6hupSdhw2vQtr5sDOL+pZyAEX3grB0eAKBmdrcLX+4TGk2vMfHpvykJt6rEREpJE09Pfba7fjKC0tZcqUKQBcffXVvPPOO+Tm5pKUlEReXh4zZsxg5syZtdYzxrBihfsQ0K233sorr7xCTk4OnTt3BmDnzp0AbNiwgSNHjgDwt7/9jdGjRzNnzhxuvvlmSkpK+O677xochs5q/gHQ+xr3dCDb3UP07eITFjKw8q8elNnqhMAUXEeIqu918A/zfnj0CwCHw13uV3//8Qa2Dh/3Vbr73tRYLSEiIlInr/UMffHFFwwYMACAN954g+uuuw6An/3sZ3z00Ud06dKF7OzsOte95JJL+OSTT2r0DB04cIDhw4fzz3/+k9atW3P48GESExM5fPgwrVu3pmvXrmzevBljDPfddx9PPfVUvXUrKSmhpKTEel1QUEBcXNzZ2TN0ovy97kNjNe6L5oCUMe6nJYVQehRKjlZ7LHTPryxv/Po4fH8IRYFwdH/t9xMGu9/38QNff/ejj+8Pj37g43/Caz/w9av5us7JtwnK9PpRZxERqabF9wzt3r3beh4ZGWk9b9/efauJXbt21bvuokWLuPbaa/nwww9Zt24dAMHBwaSmptKqVSsA2rRpw2effcYvfvELtm/fzldffQVAp06dSElJOWndnn76aZ544onT2q4Wr+q+aO/eC6bCHUaGv3DqHhhjoLzkh4B0YmA68XXBCWGqjmVKj/5QbsUP10vKr/tzcz5pvG1vco5q4ap6wKojcNUZrnzrWbaOcFbXVKvM6uWdRgD08T1he+oq8ywMgDoUK01N+5hnWkB7tbi71jeko2rq1Kl8+OGHjBo1ilmzZrF+/XqGDBnCE088QVhYGPfeey9FRUWMGzeO7du38/vf/57bb7+dV199lQceeIDRo0dz3nnnkZqaWm/5999/v/W6qmfonNH3JkgcUvu+aCfjcLgPufkHQFDEmdehsvLHUFRy1F2X+de6Q5f1mT4wZJr70Fplhbtnqt6pAirKar6uLIfKshNel/+wXAPKs5Y9Yf3Ksno2ykBFqXuyDccZ9rCdYQCsFdhOFkD93Tc9/vJl937mcMBFk6DLz4A6/t+p9X9RYy1Tx3J1/rfXlJ/XSMu0iDrVtVoz1unE5XZ+AWvf+GE5h/t+kvEDfhgO4Djh8Qf1vnfivFO8R9VDfe/VVVZD3qurzNOoX13bvHER/Pe3Xh8e4bUwVD1cVA1+rv68Y8eOda63ZcsW/vKXvwAwZswYQkJCGDBgAElJSaxfv56MjAzuvfde3njjDVavXg3AzTffTFBQEOPHj+eBBx7AGMOyZcvqDUMulwuXy9Uo29lihXbw7l8sPj4QEOKeANp1heEzPe+x8gZj3F/c6uGp4mTB6jQCW51lVlRbtgGBrUHlNTQwniQAVpad5P0WzBhYMdM9iTQJA2vnuSc5NVPp/g1IHNLsv09eC0NpaWmEh4dz6NAhFixYwHXXXUdubi6Zme6rKQ8dOhSApKQkAO6++27uvvtu8vN/PJyyevVqRo4cyaFDh9ixYwcAQUFBALWWu/zyy61wVH05aUFOp8fKGxwOd1jz8QXO8dBcXa3etBPD3UkCmyc9ck3Vw1d82N0Vf6LQOHAGYf0VXJ3jxHmnu0xdDXrCzFrlnMnnNaCsxlqmyet0GuU0eZ3qKevY97B3de33YvpCYNgPPUjmx0f4sVep3vdMPY/U8x4nea8BZdd4j4avdzp1qiyHih/H57oXqXD/BjTz//9ePbX+r3/9KxMnTgRqnlofERHBunXriImJwfHDjjht2jQef/xxysrKSE5Otq5FlJyczP79+zl8+DAA//73vxk2bBibN2+mT58+lJaW4nQ66datG9nZ2ZSUlBAaGsqmTZuIjm7Y7SrO6lPrRcStrpMHHL5w7zctN3jL2UX7mGeaob3Oiosu3nbbbcybN4+UlBRyc3NxOBykp6ezYsUKYmJi6lzH39+fTz75hNtvv52EhARycnLw8/Nj8ODBvP/++wwbNgxw9ygtX76cX/7yl0RERJCVlUW7du0YPXo0K1asaHAQEpFzRNXJA44frpNVdShWP1LSWLSPeaYFtZdux9EA6hkSOYfk7235h2Ll7KZ9zDNN2F4t/tR6ERGv8PbJA3Lu0z7mmRbQXmfhRUJEREREGo/CkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNia7k3WAFX3si0oKPByTURERKShqn63T3VPeoWhBigsLAQgLi7OyzURERERTxUWFhIaGlrv+w5zqrgkVFZWkpubS3BwMA6Hw6N1CwoKiIuLY/fu3YSEhDRRDc8dai/PqL08pzbzjNrLc2ozzzRlexljKCwsJCYmBh+f+kcGqWeoAXx8fIiNjT2jMkJCQvSl8IDayzNqL8+pzTyj9vKc2swzTdVeJ+sRqqIB1CIiImJrCkMiIiJiawpDTczlcjFt2jRcLpe3q3JWUHt5Ru3lObWZZ9RenlObeaYltJcGUIuIiIitqWdIREREbE1hSERERGxNYUhERERsTWFIREREbE1hqInMnz+fvn37EhgYSNu2bRk1ahTbtm3zdrWa3aeffspVV11Fu3btcDgcOBwO/vKXv9RYpqysjCeeeILOnTvjdDqJjY3lvvvu4+jRozWW27p1K6NGjaJt27YEBgbSt29f3nrrrebcnCb3hz/8gcGDBxMdHY3L5aJTp06MHTuW7du3W8uovWp64YUX6NOnD2FhYbhcLmJjY7nmmmtYv369tUxhYSH33XcfsbGxOJ1OEhMTeeKJJygvL69R1po1axg6dCghISG0atWKAQMGkJGR0dyb1Gz+7//+z/peXnvttdZ87WM/evzxx602OnGq2n/UXnU7cOAAkyZNolOnTjidTiIiIhgyZIj1/1mL+l4aaXR/+9vfDGAAk5CQYEJCQgxgIiMjzb59+7xdvWb1xz/+0fj5+ZmuXbtabfLKK6/UWOaGG24wgPHx8THdunUz/v7+BjCDBg0yFRUVxhhjcnNzTWRkpAFMSEiISUhIsMqbNWuWNzatSXTq1Mk4HA6TlJRUYxujoqJMfn6+MUbtdaIRI0aY6Ohok5qaapKTk42Pj48BTNu2bc3Ro0dNRUWFGTRokAGMv7+/6datm7XMjTfeaJWzbt0606pVKwOYiIgI06FDBwMYX19f8+GHH3pxC5vG7NmzrX0CMKNHj7be0z72o2nTpln7RL9+/WpM5eXlxhi1V10OHDhgbaPT6TQ9evQw3bt3N4GBgeazzz5rcd9LhaFGVlJSYiIiIgxgrr76amOMMXv37jXBwcEGMJMmTfJyDZvXwYMHzbFjx0xOTk6dYWjNmjXW/D/96U/GGGOWLFlizVuwYIExxphJkyYZwAQHB5u9e/caY4y5+uqrrS9ISUlJ829cE5g+fbrZuXOn9free++12mLhwoVqrzoUFxfXeP3oo49a7bF69WqzYMEC6/W7775rjDFm5syZ1rw1a9YYY4wZPny4AUx8fLwpKCgwZWVlpl+/fgYwvXr1avbtakpbt241rVu3NhdddJGJjY2tEYa0j9VUFYbGjh1b5/tqr7pNnDjRAKZHjx4mNzfXml9SUmKOHz/e4r6XCkON7PPPP7f+Md944w1r/uWXX24A06VLFy/WznvqC0PTp0+35ld9YSoqKkxAQIABzK233mqMMea8884zgPnZz35mrfvPf/7TWveLL75o3g1qJtX/w3jvvffUXvVYuHCh6devX42eoXbt2pmCggIzYcIEA5jAwEDrr/S9e/dabfHUU0+ZsrIyExgYaABz2223WeU+9dRT1nJVP2Bnu6ofk5CQELN9+3bTqVOnGmFI+1hNVWGodevWJiAgwERFRZlhw4aZr776yhij9qpLZWWladOmjQHM0KFDTY8ePUyrVq1M7969rd/Flva91JihRrZ7927reWRkpPW8ffv2AOzatavZ69SS1dVePj4+REREAD+2V9VydbVp9eXOJRUVFfz1r38FoHPnzgwZMkTtVY/vvvuOL7/8kk2bNlFZWUlCQgIff/wxwcHBVluEh4dbd60+sS0OHjxIcXExcO632RNPPMGXX37Jyy+/TEJCQq33tY/V5uvrS1RUFPHx8ezfv5/33nuPiy66iK+//lrtVYcDBw5w+PBhAJYuXcqRI0do06YN69evZ8yYMbzzzjst7nupMNRMjC707ZGGtNe53KZFRUWMHDmSDz/8kKioKN59992TXqre7u11++23U1lZyc6dOxk9ejQ5OTmMHj2awsLCOpdvaFuca222evVqnn76aW644Qauv/56j9a16z42ZswY8vLy2LJlC5s2bWLp0qUAlJSU8Oc//7ne9ezaXkCNAdDJycls376d7du3k5ycDMBLL71U53re/F4qDDWyuLg463leXl6t5x07dmz2OrVkdbVXZWUlhw4dAn5sr6rl6mrT6sudC/bv38+gQYN499136dq1K1988QXdu3cH1F4n43A46NixI4888ggAGzdu5M0337Ta4uDBg1RWVgK12yIiIoLAwMBa751rbbZhwwYqKip45513aN26Na1bt7b+sl6wYAGtW7cmOjraWl77GHTt2pW2bdtar6+44grCw8MBd6+EvpO1tWvXDqfTCUCfPn1wOp04nU769OkDwI4dO1rc91JhqJGlpaVZX5QFCxYAkJubS2ZmJgBDhw71Wt1aourtUdVe7733HsePH6/xftXj//73P3JzcwFYuHAhABEREVxwwQXNVuemtHHjRvr378+aNWu4+OKL+d///kfnzp2t99VeNR06dIh//OMflJaWWvPef/9963lRUZHVFsePH7feq2o7cLeVn58fQ4YMAeA///kPhYWFlJeXs2TJEgB69epFTExMk29Pczl+/DhFRUUUFRVZf2WXl5dTVFTEz3/+c2s57WPwu9/9rsahmI8++sgKOvHx8fpO1sHf35+BAwcCsH79esrKyigrK7Mud9GlS5eW971slJFHUsOrr75qDe6qfmp9RETEOTMIs6EWLFhgEhMTrUGa/DCwNTEx0YwZM8YYY8x1111nnZaalJRknZZ68cUXWwPr9uzZY52ld+JpqX/961+9uYmNqvolCFJSUmqcxvvaa68ZY9Re1VUNzA8MDDQ9e/Y0cXFx1nYGBwebHTt2mPLycjNgwAAD7lN4k5KSrEHWVfugMcasXbvWGqx54im8H3zwgRe3smmdOIDaGO1j1VVd7qJjx44mOTnZOBwOA5igoCCzceNGY4zaqy6ZmZnG6XQawHTo0KHG9+m///1vi/teKgw1kXnz5pmUlBTjcrlMaGioSU9PN9nZ2d6uVrObM2eO9YU/cRo0aJAxxpjS0lLz2GOPmfj4eOPv729iYmLMPffcYwoKCmqUlZWVZdLT001oaKhxuVwmJSXF/POf//TCVjWd6qHxxGnatGnGGLVXdYcPHzbXXnut6dy5swkMDDR+fn4mLi7O3HDDDebbb7+1lsvPzzf33HOPiYmJMf7+/iY+Pt489thjprS0tEZ5K1euNJdffrl15tBPfvKTc/IaQ9XVFYa0j/3o1VdfNZdddpmJjo42LpfLxMfHm+uvv95s3rzZWkbtVbfPP//cDB482LRq1cqEh4ebyy67zGRmZlrvt6TvpcOYc3QEl4iIiEgDaMyQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCIiIjYmsKQiIiI2JrCkIiIiNiawpCItHgOhwOHw8HcuXO9XZV6bd26lcsuu4yQkBAcDgeDBw/2dpVEpIEUhkSklsGDB1sB5KmnnrLmb968+awIJt7wwAMPsGzZMsrKykhLS6N79+61lpk7d67VfiebRKR5+Xm7AiLSsj333HPccccdtG3b1ttVaTKlpaU4nc4zKmPjxo0A3HvvvTz99NN1LtOuXTv69etnvf7yyy8B913LExMTm7yOIlI39QyJyEnl5+fzu9/9rt73P/nkE6tHY8eOHdb8E3uQqveKvP3226SmphIYGMiVV17JgQMHeO2114iLiyM8PJw777yTsrKyWp9VUFDA2LFjCQ4Opl27djz22GNUv71ifn4+kydPplOnTjidTmJjY7n//vs5duyYtcy4ceOsw1jPPvsssbGxBAQE1Lt9FRUV/OEPf6B79+64XC5CQ0O5/PLL+eyzzwDYsWMHDoeDbdu2AfDMM8/gcDgYN25crbKGDRtGZmamNdU1v2r9qna68MILcTqdvPHGG4C7d+6aa66hXbt2OJ1OkpOTeeWVV2p8TmVlJS+++CI9e/YkICCANm3acM0115CTk1PvdorYWqPe9lVEzgmDBg0ygDnvvPNMcHCwCQwMNHv37jWbNm0ygAHMnDlzjDHGfPzxx9a8nJwcq4wTl5szZ441LzAw0CQlJRmHw2EAk5ycbPz9/U3Xrl2tZf7yl7/UKisoKMjExMSYDh06WPNefPFFY4wxJSUlJiUlxQAmICDA9O7d2wQEBBjAXHrppaaystIYY8zYsWMNYJxOp/Hx8THJyckmPDy83ra45ZZbrM8677zzTNu2bQ1g/Pz8zCeffGJyc3NNv379jNPpNIDp0KGD6devn3nyySdP2c5V5Y4dO9aaV709nU6niY6ONl27djVz58412dnZJjQ01ACmbdu2pmfPnlYbPvHEE1YZd9xxh1VGjx49THh4uAFMVFSU+e67705ZLxG7URgSkVqqwlC/fv3MtGnTDGAmTpzYaGFo+vTpxhhjrr/+emvevHnzjDHGDBgwwABm9OjRtcq6+OKLTWlpqSktLTUXX3yxAUz79u2NMcbMnTvXChDZ2dnGGGPWrl1rrZuRkWGM+TEMAeb99983xhhTXl5eZzts3brVChuTJ082xhhz5MgR06lTJwOYgQMHWstWzZs2bVqD2/lUYWjMmDGmoqLCquO4ceMMYHr27GmKioqMMca88MILVsAsKCgw27dvt+r8+uuvG2OMKSwsNLGxsQYwjz76aIPrJ2IXOkwmIif1wAMPEBERwaxZs9i6dWujlDl8+HAA4uPja83r3LkzAN99912t9UaNGoW/vz/+/v6MGjXKWu7AgQOsXLkScI+t6dq1Kw6Hg5SUFGvd6oelALp168aVV14JgK+vb531XLNmjXUYbsyYMQCEhoZy1VVXAbB69eqGb/RpmDRpEj4+PlYdq7Zxw4YNBAUF4XA4uPfeewEoLi5m/fr1rF692qrz2LFjcTgcBAcHs2fPHqB2O4iIBlCLyCkEBwczdepUHnjgAaZNm1br/epnP1VUVADusTsnExISAoCfn1+teVXlmWpjgTzhdDpJTU2tNb9NmzY1Xrdv3/60ym9O9dWxvgHXJ4a6lJQUXC5XjXmdOnVqvAqKnCMUhkTklO666y5eeOEFvvrqq1rvRUZGWs+zs7NJTEzk7bffbpJ6LFy4kDvvvNN6Du7A0K5dO9LS0gB3IHv55Zfp27cvAMePH+e9995jyJAhNcpqyCns559/Pg6HA2MMb7zxBhdeeCH5+fm8//77AFxwwQWNtm11ObGOaWlpfPvtt4SGhvL+++9bZ/gdPHiQZcuW0b9/fyIjI606jxs3jsmTJwPucPn5558TGhrapHUWORvpMJmInJLL5aqzVwigS5cudOzYEXAfSrrkkku46667mqQeq1evJj4+nvj4eJYvXw7AlClTALjuuuvo3bs3FRUVpKWl0bNnT7p160ZYWBijRo3iyJEjHn9eYmIiN998MwAvvvgiXbp0oXPnzuzcuRM/Pz+eeOKJRtu2hpg6dSohISFs27aNuLg4UlNT6dSpE1FRUTz88MOA+zDjrbfeCrhP8+/cuTO9e/cmLCyMgQMH1hloRexOYUhEGmTcuHF069at1nw/Pz/eeustUlNTOX78ON9//z2LFi1qkjrMmDGDIUOGkJ+fT3h4OL/+9a+55557AHdgW758Offccw9xcXFkZ2dz+PBhLrjgAp566qnTPiz26quv8txzz5GcnMyuXbsoKyvjsssu47///W+zX2W6W7du/O9//+Oaa66hVatWbNy4kcrKSoYOHcpvf/tba7lXXnmFP/7xj/Tq1Yvc3Fx27txJfHw8999/v66MLVIHhzndA/MiIiIi5wD1DImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrSkMiYiIiK0pDImIiIitKQyJiIiIrf1/R2jsSGnoISwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree:10</th>\n",
       "      <th>tree:50</th>\n",
       "      <th>tree:100</th>\n",
       "      <th>tree:300</th>\n",
       "      <th>tree:500</th>\n",
       "      <th>tree:600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Score</th>\n",
       "      <td>0.974927</td>\n",
       "      <td>0.987374</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>0.988314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score</th>\n",
       "      <td>0.884353</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.879746</td>\n",
       "      <td>0.878931</td>\n",
       "      <td>0.878972</td>\n",
       "      <td>0.878889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.193384</td>\n",
       "      <td>0.204640</td>\n",
       "      <td>0.206740</td>\n",
       "      <td>0.205852</td>\n",
       "      <td>0.206670</td>\n",
       "      <td>0.206774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tree:10   tree:50  tree:100  tree:300  tree:500  tree:600\n",
       "Train Score  0.974927  0.987374  0.988314  0.988314  0.988314  0.988314\n",
       "Test Score   0.884353  0.880383  0.879746  0.878931  0.878972  0.878889\n",
       "F1 Score     0.193384  0.204640  0.206740  0.205852  0.206670  0.206774"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tree = [10, 50, 100, 300, 500, 600]\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_GS_original)\n",
    "X_scaled_train = scaler.transform(X_GS_original)\n",
    "X_scaled_test = scaler.transform(X_test_original.loc[:, rfe_original.support_])\n",
    "    \n",
    "    \n",
    "for num in num_tree:\n",
    "    RF_model = RandomForestClassifier(max_depth=30, n_estimators=num, random_state=42)\n",
    "\n",
    "    RF_model.fit(X_scaled_train, y_GS_original)\n",
    "    \n",
    "    train_scores.append(RF_model.score(X_scaled_train, y_GS_original))\n",
    "    test_scores.append(RF_model.score(X_scaled_test, y_test_original))\n",
    "    \n",
    "    y_pred = RF_model.predict(X_scaled_test)\n",
    "    f1_scores.append(f1_score(y_test_original, y_pred, pos_label=1))    \n",
    "    \n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(num_tree, train_scores, label=\"Train Score\",marker='.')\n",
    "plt.plot(num_tree, test_scores,label=\"Test Score\",marker='.')\n",
    "plt.xlabel('Number of Tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "score_data = [train_scores, test_scores, f1_scores]\n",
    "score_original = pd.DataFrame(score_data, columns=[\"tree:10\", \"tree:50\" , \"tree:100\", \"tree:300\", \"tree:500\", \"tree:600\"], \n",
    "                              index=[\"Train Score\", \"Test Score\", \"F1 Score\"])\n",
    "\n",
    "score_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4cfa12",
   "metadata": {},
   "source": [
    "The test score with n_estimators=10 is the best. However, The f1 score with n_estimators=100 is the highest. Therefore, I'll use n_estimators=100 for creating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb6a5a",
   "metadata": {},
   "source": [
    "I'll check the model accuracy with/without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "898077a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With no PCA\n",
      "\n",
      "Train score: 0.9625432615031945\n",
      "Test score: 0.8876642778044754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     87544\n",
      "           1       0.27      0.18      0.21      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.60      0.57      0.58     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_train = scaler.transform(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_test = scaler.transform(X_test_original.loc[:, rfe_original.support_])\n",
    "        \n",
    "RF_model = RandomForestClassifier(max_depth=30, n_estimators=100, random_state=42)\n",
    "RF_model.fit(X_scaled_train, y_train_original)\n",
    "    \n",
    "train_score = RF_model.score(X_scaled_train, y_train_original)\n",
    "test_score = RF_model.score(X_scaled_test, y_test_original)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_original, y_pred)\n",
    "\n",
    "print(\"With no PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dd80c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA\n",
      "\n",
      "Train score: 0.9624402845745038\n",
      "Test score: 0.8922400284156202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     87544\n",
      "           1       0.27      0.16      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.60      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_train = scaler.transform(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_test = scaler.transform(X_test_original.loc[:, rfe_original.support_])\n",
    "      \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model = RandomForestClassifier(max_depth=30, n_estimators=100, random_state=42)\n",
    "RF_model.fit(X_train_PCA, y_train_original)\n",
    "    \n",
    "train_score = RF_model.score(X_train_PCA, y_train_original)\n",
    "test_score = RF_model.score(X_test_PCA, y_test_original)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_original, y_pred)\n",
    "\n",
    "print(\"With PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c09b3",
   "metadata": {},
   "source": [
    "The test score of the model with PCA is better than the one without PCA. However, f1 score of the model with PCA is better than the other. Therefore, I'll evaluate the model without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40db3599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.9625432615031945\n",
      "Test score: 0.8876642778044754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     87544\n",
      "           1       0.27      0.18      0.21      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.60      0.57      0.58     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_train = scaler.transform(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_test = scaler.transform(X_test_original.loc[:, rfe_original.support_])\n",
    "    \n",
    "RF_model_original = RandomForestClassifier(max_depth=30, n_estimators=100, random_state=42)\n",
    "\n",
    "RF_model_original.fit(X_scaled_train, y_train_original)\n",
    "    \n",
    "train_score = RF_model_original.score(X_scaled_train, y_train_original)\n",
    "test_score = RF_model_original.score(X_scaled_test, y_test_original)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model_original.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_original, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a02dc918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.962583556823117\n",
      "Test score: 0.8874448925012014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     87544\n",
      "           1       0.26      0.18      0.21      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.57      0.58     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "R_forest_w_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05d8e2",
   "metadata": {},
   "source": [
    "The test score bemace better slightly. However, recall score for 1 is too low, so this model cannot be my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46046713",
   "metadata": {},
   "source": [
    "**Under sampled data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602662d5",
   "metadata": {},
   "source": [
    "train size = 0.1　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a533665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10,\n",
      "                       random_state=42)\n",
      "Train score:\n",
      " 0.786013619696176\n",
      "Test score:\n",
      " 0.7035477737615178\n",
      "Best F1 Score: 0.31672726397149115\n",
      "CPU times: total: 12min 1s\n",
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [10, 20, 30, None]\n",
    "split = [2, 5, 10]\n",
    "leaf =  [1, 2, 4]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_under, y_GS_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058245ff",
   "metadata": {},
   "source": [
    "All hyperparameters of max_depth, sample_split, and sample_leaf are on edge of the range. So, all the best parameters might be higher/lower. Therefore, I'll set the range of sample_split and sample_leaf parameters higher than above and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b7e63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=20, min_samples_leaf=6, min_samples_split=20,\n",
      "                       n_estimators=10, random_state=42)\n",
      "Train score:\n",
      " 0.7778941854374017\n",
      "Test score:\n",
      " 0.7183197175153048\n",
      "Best F1 Score: 0.323981446659145\n",
      "CPU times: total: 12min 34s\n",
      "Wall time: 12min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [10, 20, 30, None]\n",
    "split = [10, 15, 20]\n",
    "leaf =  [4, 6, 8, 10]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_under, y_GS_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480157e",
   "metadata": {},
   "source": [
    "The min_samples_split parameter is still on the edge. Therefore, I'll set the range of sample_split parameter higher than above and more detail number for other patameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d9a89ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=20, min_samples_leaf=6, min_samples_split=20,\n",
      "                       n_estimators=10, random_state=42)\n",
      "Train score:\n",
      " 0.7778941854374017\n",
      "Test score:\n",
      " 0.7183197175153048\n",
      "Best F1 Score: 0.323981446659145\n",
      "CPU times: total: 32.7 s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 20, 30]\n",
    "depth = [15, 20, 25, None]\n",
    "split = [15, 20, 25]\n",
    "leaf =  [4, 6, 8, 10]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_under, y_GS_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66477842",
   "metadata": {},
   "source": [
    "Even I used more detail number, the best hyperparameters didn't change. Therefore, I'll use these hyperparameters and check if this model work better with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3e5c7",
   "metadata": {},
   "source": [
    "I'll check the model accuracy with/without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c4d8663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With no PCA\n",
      "\n",
      "Train score: 0.7682677701534755\n",
      "Test score: 0.7126992749838073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.20      0.80      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "     \n",
    "RF_model = RandomForestClassifier(max_depth=20, min_samples_leaf=6, \n",
    "                                  min_samples_split=20,n_estimators=10, random_state=42)\n",
    "RF_model.fit(X_scaled_train, y_train_under)\n",
    "    \n",
    "train_score = RF_model.score(X_scaled_train, y_train_under)\n",
    "test_score = RF_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"With no PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec228f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA\n",
      "\n",
      "Train score: 0.7811010423759887\n",
      "Test score: 0.7131171517519483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.20      0.79      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "   \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model = RandomForestClassifier(max_depth=20, min_samples_leaf=6, \n",
    "                                  min_samples_split=20,n_estimators=10, random_state=42)\n",
    "RF_model.fit(X_train_PCA, y_train_under)\n",
    "    \n",
    "train_score = RF_model.score(X_train_PCA, y_train_under)\n",
    "test_score = RF_model.score(X_test_PCA, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"With PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76c9c4",
   "metadata": {},
   "source": [
    "The test score of the model with PCA is slightly better. Also, the both recall scores are almost same. Therefore, I'll evaluate the model with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfd2e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.7811010423759887\n",
      "Test score: 0.7131171517519483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.20      0.79      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "   \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model_under = RandomForestClassifier(max_depth=20, min_samples_leaf=6, \n",
    "                                  min_samples_split=20,n_estimators=10, random_state=42)\n",
    "RF_model_under.fit(X_train_PCA, y_train_under)\n",
    "    \n",
    "train_score = RF_model_under.score(X_train_PCA, y_train_under)\n",
    "test_score = RF_model_under.score(X_test_PCA, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model_under.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9d70298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.8011628516054685\n",
      "Test score: 0.7102024612941643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.20      0.77      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.74      0.56     95722\n",
      "weighted avg       0.90      0.71      0.77     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "R_forest_w_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebc4d3",
   "metadata": {},
   "source": [
    "The test score and other evaluation scores after optimizing became slightly better. Also, the recall score for 1 is almost 0.80 and as high as the models I'm keeping for final model comparison. Therefore, I'll compare this model to other models of RandomForest at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a72913",
   "metadata": {},
   "source": [
    "**Over sampled data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0752268",
   "metadata": {},
   "source": [
    "train size = 0.1　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b64fc66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=20, n_estimators=500, random_state=42)\n",
      "Train score:\n",
      " 0.9497454225007343\n",
      "Test score:\n",
      " 0.7317440086918368\n",
      "Best F1 Score: 0.31158176943699734\n",
      "CPU times: total: 3h 11min 51s\n",
      "Wall time: 3h 13min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [10, 20, 30, None]\n",
    "split = [2, 5, 10]\n",
    "leaf =  [1, 2, 4]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_over, y_GS_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7f502",
   "metadata": {},
   "source": [
    "The parameter of n_estimators is on the edge of the range, so I'll try other values of n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c65ade82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree:10</th>\n",
       "      <th>tree:50</th>\n",
       "      <th>tree:100</th>\n",
       "      <th>tree:300</th>\n",
       "      <th>tree:500</th>\n",
       "      <th>tree:600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Score</th>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.983379</td>\n",
       "      <td>0.983477</td>\n",
       "      <td>0.983501</td>\n",
       "      <td>0.983550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score</th>\n",
       "      <td>0.746673</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.736873</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.736800</td>\n",
       "      <td>0.737020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.291317</td>\n",
       "      <td>0.298270</td>\n",
       "      <td>0.297845</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.297709</td>\n",
       "      <td>0.298001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tree:10   tree:50  tree:100  tree:300  tree:500  tree:600\n",
       "Train Score  0.970430  0.982645  0.983379  0.983477  0.983501  0.983550\n",
       "Test Score   0.746673  0.738931  0.736873  0.736988  0.736800  0.737020\n",
       "F1 Score     0.291317  0.298270  0.297845  0.297584  0.297709  0.298001"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tree = [10, 50, 100, 300, 500, 600]\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_GS_over)\n",
    "X_scaled_train = scaler.transform(X_GS_over)\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "    \n",
    "    \n",
    "for num in num_tree:\n",
    "    RF_model = RandomForestClassifier(max_depth=30, n_estimators=num, random_state=42)\n",
    "\n",
    "    RF_model.fit(X_scaled_train, y_GS_over)\n",
    "    \n",
    "    train_scores.append(RF_model.score(X_scaled_train, y_GS_over))\n",
    "    test_scores.append(RF_model.score(X_scaled_test, y_test_sampled))\n",
    "\n",
    "    y_pred = RF_model.predict(X_scaled_test)\n",
    "    f1_scores.append(f1_score(y_test_sampled, y_pred, pos_label=1))    \n",
    "    \n",
    "    \n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(num_tree, train_scores, label=\"Train Score\",marker='.')\n",
    "plt.plot(num_tree, test_scores,label=\"Test Score\",marker='.')\n",
    "plt.xlabel('Number of Tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "\n",
    "score_data = [train_scores, test_scores, f1_scores]\n",
    "score_over = pd.DataFrame(score_data, columns=[\"tree:10\", \"tree:50\" , \"tree:100\", \"tree:300\", \"tree:500\", \"tree:600\"],\n",
    "                          index=[\"Train Score\", \"Test Score\", \"F1 Score\"])\n",
    "\n",
    "score_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526746d",
   "metadata": {},
   "source": [
    "The test score with n_estimators=10 is the highest. However, The f1 score with n_estimators=50 is the best. Therefore, I'll use n_estimators=50 for creating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d9a70",
   "metadata": {},
   "source": [
    "I'll check the model accuracy with/without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a00011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With no PCA\n",
      "\n",
      "Train score: 0.9723440712816998\n",
      "Test score: 0.8462840308393055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     87544\n",
      "           1       0.21      0.28      0.24      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.57      0.59      0.58     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "     \n",
    "RF_model = RandomForestClassifier(max_depth=30, n_estimators=50, random_state=42)\n",
    "RF_model.fit(X_scaled_train, y_train_over)\n",
    "    \n",
    "train_score = RF_model.score(X_scaled_train, y_train_over)\n",
    "test_score = RF_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"With no PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cda8fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA\n",
      "\n",
      "Train score: 0.9716292959953001\n",
      "Test score: 0.8479137502350557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     87544\n",
      "           1       0.22      0.30      0.25      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.58      0.60      0.58     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    " \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model = RandomForestClassifier(max_depth=30, n_estimators=50, random_state=42)\n",
    "RF_model.fit(X_train_PCA, y_train_over)\n",
    "    \n",
    "train_score = RF_model.score(X_train_PCA, y_train_over)\n",
    "test_score = RF_model.score(X_test_PCA, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"With PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7387317",
   "metadata": {},
   "source": [
    "The model with PCA improved a little bit. Therefore, I'll use the model with PCA for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04ba06bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.9716292959953001\n",
      "Test score: 0.8479137502350557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     87544\n",
      "           1       0.22      0.30      0.25      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.58      0.60      0.58     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    " \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model = RandomForestClassifier(max_depth=30, n_estimators=50, random_state=42)\n",
    "RF_model.fit(X_train_PCA, y_train_over)\n",
    "    \n",
    "train_score = RF_model.score(X_train_PCA, y_train_over)\n",
    "test_score = RF_model.score(X_test_PCA, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "   \n",
    "print(\"After optimization\\n\")    \n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4186b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.9752937432683835\n",
      "Test score: 0.8481540293767368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92     87544\n",
      "           1       0.20      0.26      0.23      8178\n",
      "\n",
      "    accuracy                           0.85     95722\n",
      "   macro avg       0.57      0.58      0.57     95722\n",
      "weighted avg       0.87      0.85      0.86     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "R_forest_w_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d147c0",
   "metadata": {},
   "source": [
    "The test score became lower, but the precision and recall score for 1 improved. However, the recall and f1 score for 1 are too low. Therefor, this model cannot be my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ce4ee",
   "metadata": {},
   "source": [
    "**SMOTE data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1dbac",
   "metadata": {},
   "source": [
    "train size = 0.1　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf17f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=5,\n",
      "                       random_state=42)\n",
      "Train score:\n",
      " 0.8060315284441398\n",
      "Test score:\n",
      " 0.7519065627546436\n",
      "Best F1 Score: 0.3060604289638244\n",
      "CPU times: total: 45min 9s\n",
      "Wall time: 47min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 100, 500]\n",
    "depth = [10, 20, 30, None]\n",
    "split = [2, 5, 10]\n",
    "leaf =  [1, 2, 4]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_smote, y_GS_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8767d3",
   "metadata": {},
   "source": [
    "All the hyperparameters are within the range. I'll set mode detail number and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdf548f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " RandomForestClassifier(max_depth=18, min_samples_leaf=2, min_samples_split=5,\n",
      "                       n_estimators=50, random_state=42)\n",
      "Train score:\n",
      " 0.805958092627044\n",
      "Test score:\n",
      " 0.751655836693759\n",
      "Best F1 Score: 0.30560261728106564\n",
      "CPU times: total: 4min 46s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_tree = [10, 50, 100]\n",
    "depth = [16, 18, 20, None]\n",
    "split = [4, 5, 6]\n",
    "leaf =  [1, 2, 3]\n",
    "\n",
    "RF_gridsearch(num_tree, depth, split, leaf, X_GS_smote, y_GS_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf02d16",
   "metadata": {},
   "source": [
    "The both score of test and f1 became lower. Therefore, I'll use the hyperparameters one before and check if this model work better with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79a62587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With no PCA\n",
      "\n",
      "Train score: 0.8058503867619701\n",
      "Test score: 0.753598963665615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Without PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "     \n",
    "RF_model = RandomForestClassifier(max_depth=18, min_samples_leaf=2, \n",
    "                                  min_samples_split=5,n_estimators=50, random_state=42)\n",
    "RF_model.fit(X_scaled_train, y_train_smote)\n",
    "    \n",
    "train_score = RF_model.score(X_scaled_train, y_train_smote)\n",
    "test_score = RF_model.score(X_scaled_test, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"With no PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27418f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA\n",
      "\n",
      "Train score: 0.8058650739253892\n",
      "Test score: 0.7535153883119868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "   \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model = RandomForestClassifier(max_depth=18, min_samples_leaf=2, \n",
    "                                  min_samples_split=5,n_estimators=50, random_state=42)\n",
    "RF_model.fit(X_train_PCA, y_train_smote)\n",
    "    \n",
    "train_score = RF_model.score(X_train_PCA, y_train_smote)\n",
    "test_score = RF_model.score(X_test_PCA, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"With PCA\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c24a1",
   "metadata": {},
   "source": [
    "All scores are almost the same. However, the test score without PCA is slightly better. So, I'll use the model without PCA for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71de6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.8058503867619701\n",
      "Test score: 0.753598963665615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "     \n",
    "RF_model_smote = RandomForestClassifier(max_depth=18, min_samples_leaf=2, \n",
    "                                  min_samples_split=5,n_estimators=50, random_state=42)\n",
    "RF_model_smote.fit(X_scaled_train, y_train_smote)\n",
    "    \n",
    "train_score = RF_model_smote.score(X_scaled_train, y_train_smote)\n",
    "test_score = RF_model_smote.score(X_scaled_test, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model_smote.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e604c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.7534422598775621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "R_forest_w_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82699e72",
   "metadata": {},
   "source": [
    "The test score of the model after optimizing improved slightly, but the other scores are exact same. However, the model has better test score than the other models, so I'll compare this model to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b46926",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8019a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Sampled data\n",
      "\n",
      "Train score: 0.7811010423759887\n",
      "Test score: 0.7131171517519483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.20      0.79      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Under sampled data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "   \n",
    "my_PCA = PCA()\n",
    "my_PCA.fit(X_scaled_train)\n",
    "\n",
    "X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "RF_model_under = RandomForestClassifier(max_depth=20, min_samples_leaf=6, \n",
    "                                  min_samples_split=20,n_estimators=10, random_state=42)\n",
    "RF_model_under.fit(X_train_PCA, y_train_under)\n",
    "    \n",
    "train_score = RF_model_under.score(X_train_PCA, y_train_under)\n",
    "test_score = RF_model_under.score(X_test_PCA, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model_under.predict(X_test_PCA)\n",
    "\n",
    "report_initial = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"Under Sampled data\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7fa87a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE data\n",
      "\n",
      "Train score: 0.8058503867619701\n",
      "Test score: 0.753598963665615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SMOTE data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "     \n",
    "RF_model_smote = RandomForestClassifier(max_depth=18, min_samples_leaf=2, \n",
    "                                  min_samples_split=5,n_estimators=50, random_state=42)\n",
    "RF_model_smote.fit(X_scaled_train, y_train_smote)\n",
    "    \n",
    "train_score = RF_model_smote.score(X_scaled_train, y_train_smote)\n",
    "test_score = RF_model_smote.score(X_scaled_test, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = RF_model_smote.predict(X_scaled_test)\n",
    "\n",
    "report_initial = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"SMOTE data\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fab616",
   "metadata": {},
   "source": [
    "The test score of SMOTE data model is higher. However, recall score for 1 of Under sampled data is better than the one of SMOTE data. I need a model which can predict persno who has heart disease. Thefore, I'll choose the model of Under sampled data from RandomForest correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef922f",
   "metadata": {},
   "source": [
    "**From Logistic Regression: Under Sampled dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf46fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
