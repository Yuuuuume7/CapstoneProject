{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227479fa",
   "metadata": {},
   "source": [
    "# 6. Capstone Project - Hyperparameter Optimization; Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca5492",
   "metadata": {},
   "source": [
    "#### Loading data and libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edf0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f56c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68315005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data set\n",
    "original_df = pd.read_csv(\"./capstone_clean_heart_disease_fe.csv\")\n",
    "\n",
    "# Train set : Under sampled data set and Over sampled data set\n",
    "under_sampled_df = pd.read_csv(\"./under_sampled_df_fe.csv\")\n",
    "over_sampled_df = pd.read_csv(\"./over_sampled_df_fe.csv\")\n",
    "# Test set : Under sampled data set and Over sampled data set\n",
    "test_sampled_df = pd.read_csv(\"./test_sampled_df_fe.csv\")\n",
    "               \n",
    "# Train set : SMOTE data set         \n",
    "smote_df = pd.read_csv(\"./smote_df.csv\")\n",
    "# Test set : SMOTE data set  \n",
    "test_smote_df = pd.read_csv(\"./test_smote_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d33cb",
   "metadata": {},
   "source": [
    "Split each dataset into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2828fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original data set into train and test set\n",
    "X = original_df.drop(columns=\"HeartDisease\")\n",
    "y = original_df[\"HeartDisease\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_original, X_test_original, y_train_original, y_test_original = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5f8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split other data set into X and y\n",
    "X_train_under = under_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_train_under = under_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_train_over = over_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_train_over = over_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_test_sampled = test_sampled_df.drop(columns=\"HeartDisease\")\n",
    "y_test_sampled = test_sampled_df[\"HeartDisease\"]\n",
    "\n",
    "X_train_smote = smote_df.drop(columns=\"HeartDisease\")\n",
    "y_train_smote = smote_df[\"HeartDisease\"]\n",
    "\n",
    "X_test_smote = test_smote_df.drop(columns=\"HeartDisease\")\n",
    "y_test_smote = test_smote_df[\"HeartDisease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274afe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [X_train_original, X_train_under, X_train_over, X_train_smote]\n",
    "X_test = [X_test_original, X_test_sampled, X_test_sampled, X_test_smote]\n",
    "y_train = [y_train_original, y_train_under, y_train_over,y_train_smote]\n",
    "y_test = [y_test_original, y_test_sampled, y_test_sampled, y_test_smote]\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "for index in range(4):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[index])\n",
    "    X_scaled_train = scaler.transform(X_train[index])\n",
    "    X_scaled_test = scaler.transform(X_test[index])\n",
    "    \n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_scaled_train,y_train[index])\n",
    "    \n",
    "    train_score.append(model.score(X_scaled_train,y_train[index])*100)\n",
    "    test_score.append(model.score(X_scaled_test,y_test[index])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf6e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Under Sampled</th>\n",
       "      <th>Over Sampled</th>\n",
       "      <th>SMOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train score</th>\n",
       "      <td>91.452915</td>\n",
       "      <td>75.787020</td>\n",
       "      <td>75.675365</td>\n",
       "      <td>80.968618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test score</th>\n",
       "      <td>91.389649</td>\n",
       "      <td>73.322747</td>\n",
       "      <td>73.284094</td>\n",
       "      <td>77.891185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original  Under Sampled  Over Sampled      SMOTE\n",
       "Train score  91.452915      75.787020     75.675365  80.968618\n",
       "Test score   91.389649      73.322747     73.284094  77.891185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_selection = pd.DataFrame((train_score, test_score), columns=[\"Original\", \"Under Sampled\", \"Over Sampled\", \"SMOTE\"], \n",
    "                                index=[\"Train score\", \"Test score\"])\n",
    "before_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5499a7",
   "metadata": {},
   "source": [
    "**Festure selection: RFE**  \n",
    "The columns that I'll use for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932af7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Original data final\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original)\n",
    "X_scaled_train = scaler.transform(X_train_original)\n",
    "X_scaled_test = scaler.transform(X_test_original)\n",
    "\n",
    "rfe_original = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=7)\n",
    "rfe_original.fit(X_scaled_train,y_train_original)\n",
    "    \n",
    "train_score_or_rfe = rfe_original.score(X_scaled_train,y_train_original)\n",
    "test_score_or_rfe = rfe_original.score(X_scaled_test,y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0c14db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176993</th>\n",
       "      <td>27.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267593</th>\n",
       "      <td>30.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175707</th>\n",
       "      <td>32.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317039</th>\n",
       "      <td>33.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262926</th>\n",
       "      <td>23.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>26.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>25.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>36.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>27.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>19.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BMI  Smoking  DiffWalking  Sex  AgeCategory  GenHealth  Asthma\n",
       "176993  27.12        1            0    1           35          3       0\n",
       "267593  30.23        0            0    0           18          2       0\n",
       "175707  32.55        0            0    1           60          3       0\n",
       "317039  33.07        0            0    0           55          3       0\n",
       "262926  23.06        0            0    1           30          4       0\n",
       "...       ...      ...          ...  ...          ...        ...     ...\n",
       "119879  26.62        0            0    0           40          4       0\n",
       "259178  25.04        0            0    1           25          4       0\n",
       "131932  36.05        0            0    0           18          1       0\n",
       "146867  27.44        0            0    0           40          3       0\n",
       "121958  19.77        1            0    1           55          4       0\n",
       "\n",
       "[223351 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_original.loc[:, rfe_original.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca83560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Under sampled data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under)\n",
    "X_scaled_train = scaler.transform(X_train_under)\n",
    "X_scaled_test = scaler.transform(X_test_sampled)\n",
    "   \n",
    "rfe_under = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=9)\n",
    "rfe_under.fit(X_scaled_train,y_train_under)\n",
    "    \n",
    "train_score_u_rfe = rfe_under.score(X_scaled_train,y_train_under)\n",
    "test_score_u_rfe = rfe_under.score(X_scaled_test,y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda056a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_Asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38180</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38181</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38182 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Smoking  AlcoholDrinking  PhysicalHealth  DiffWalking  Sex  \\\n",
       "0            1                0             0.0            0    1   \n",
       "1            0                0             5.0            0    0   \n",
       "2            0                0             0.0            0    0   \n",
       "3            0                0             7.0            1    0   \n",
       "4            1                0             0.0            0    1   \n",
       "...        ...              ...             ...          ...  ...   \n",
       "38177        0                0             0.0            0    1   \n",
       "38178        0                0            30.0            1    0   \n",
       "38179        0                0             0.0            0    0   \n",
       "38180        1                0            15.0            0    1   \n",
       "38181        1                0             4.0            0    1   \n",
       "\n",
       "       AgeCategory  GenHealth  Asthma  Race_Asian  \n",
       "0               65          1       0           0  \n",
       "1               80          0       0           0  \n",
       "2               40          4       0           0  \n",
       "3               60          2       0           0  \n",
       "4               70          3       0           0  \n",
       "...            ...        ...     ...         ...  \n",
       "38177           75          3       0           0  \n",
       "38178           50          0       0           0  \n",
       "38179           75          2       0           0  \n",
       "38180           70          3       0           0  \n",
       "38181           50          2       0           0  \n",
       "\n",
       "[38182 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_under.loc[:, rfe_under.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd1752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : Over sampled data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over)\n",
    "X_scaled_train = scaler.transform(X_train_over)\n",
    "X_scaled_test = scaler.transform(X_test_sampled)\n",
    "   \n",
    "rfe_over = RFE(estimator=LogisticRegression(max_iter=1000, random_state=42), n_features_to_select=11)\n",
    "rfe_over.fit(X_scaled_train,y_train_over)\n",
    "    \n",
    "train_score_ov_rfe = rfe_over.score(X_scaled_train,y_train_over)\n",
    "test_score_ov_rfe = rfe_over.score(X_scaled_test,y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f8a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_Asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408515</th>\n",
       "      <td>42.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408516</th>\n",
       "      <td>24.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408517</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408518</th>\n",
       "      <td>31.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408519</th>\n",
       "      <td>27.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408520 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BMI  Smoking  AlcoholDrinking  PhysicalHealth  MentalHealth  \\\n",
       "0       27.12        1                0             0.0           2.0   \n",
       "1       30.23        0                0             0.0           0.0   \n",
       "2       32.55        0                0             0.0           0.0   \n",
       "3       33.07        0                0             0.0           0.0   \n",
       "4       23.06        0                0             0.0           0.0   \n",
       "...       ...      ...              ...             ...           ...   \n",
       "408515  42.87        0                0            30.0           0.0   \n",
       "408516  24.41        0                0             0.0           0.0   \n",
       "408517  33.00        0                0             0.0           0.0   \n",
       "408518  31.32        1                0             3.0           2.0   \n",
       "408519  27.71        1                0            15.0          30.0   \n",
       "\n",
       "        DiffWalking  Sex  AgeCategory  GenHealth  Asthma  Race_Asian  \n",
       "0                 0    1           35          3       0           0  \n",
       "1                 0    0           18          2       0           0  \n",
       "2                 0    1           60          3       0           0  \n",
       "3                 0    0           55          3       0           0  \n",
       "4                 0    1           30          4       0           0  \n",
       "...             ...  ...          ...        ...     ...         ...  \n",
       "408515            1    0           60          2       0           0  \n",
       "408516            0    1           65          2       0           0  \n",
       "408517            0    1           60          1       0           0  \n",
       "408518            0    0           65          2       1           0  \n",
       "408519            1    1           75          1       0           0  \n",
       "\n",
       "[408520 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.loc[:, rfe_over.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759d5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE : SMOTE data final\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote)\n",
    "X_scaled_train = scaler.transform(X_train_smote)\n",
    "X_scaled_test = scaler.transform(X_test_smote)\n",
    "    \n",
    "rfe_smote = RFE(estimator=LogisticRegression(max_iter=1500, random_state=42), n_features_to_select=10)\n",
    "rfe_smote.fit(X_scaled_train,y_train_smote)\n",
    "    \n",
    "train_score_s_rfe = rfe_smote.score(X_scaled_train,y_train_smote)\n",
    "test_score_s_rfe = rfe_smote.score(X_scaled_test,y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9744f360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Race_American Indian/Alaskan Native</th>\n",
       "      <th>Race_Asian</th>\n",
       "      <th>Race_Black</th>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <th>Race_Other</th>\n",
       "      <th>Race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408515</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408516</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408517</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408518</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408519</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408520 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AlcoholDrinking  AgeCategory  GenHealth  Asthma  \\\n",
       "0                     0           35          3       0   \n",
       "1                     0           18          2       0   \n",
       "2                     0           60          3       0   \n",
       "3                     0           55          3       0   \n",
       "4                     0           30          4       0   \n",
       "...                 ...          ...        ...     ...   \n",
       "408515                0           80          1       0   \n",
       "408516                0           65          3       0   \n",
       "408517                0           70          2       0   \n",
       "408518                0           75          2       0   \n",
       "408519                0           75          3       0   \n",
       "\n",
       "        Race_American Indian/Alaskan Native  Race_Asian  Race_Black  \\\n",
       "0                                         0           0           0   \n",
       "1                                         0           0           0   \n",
       "2                                         0           0           0   \n",
       "3                                         0           0           0   \n",
       "4                                         0           0           1   \n",
       "...                                     ...         ...         ...   \n",
       "408515                                    0           0           0   \n",
       "408516                                    0           0           0   \n",
       "408517                                    0           0           0   \n",
       "408518                                    0           0           0   \n",
       "408519                                    0           0           0   \n",
       "\n",
       "        Race_Hispanic  Race_Other  Race_White  \n",
       "0                   0           0           1  \n",
       "1                   1           0           0  \n",
       "2                   0           0           1  \n",
       "3                   1           0           0  \n",
       "4                   0           0           0  \n",
       "...               ...         ...         ...  \n",
       "408515              0           0           1  \n",
       "408516              0           0           1  \n",
       "408517              0           0           0  \n",
       "408518              0           0           1  \n",
       "408519              0           0           1  \n",
       "\n",
       "[408520 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote.loc[:, rfe_smote.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd13ff",
   "metadata": {},
   "source": [
    "### Optimizing Hyperparameters: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae7133",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071844ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c44132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_Tree(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    DT_model = DecisionTreeClassifier()\n",
    "    DT_model.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = DT_model.score(X_train, y_train)\n",
    "    test_score = DT_model.score(X_test, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = DT_model.predict(X_test)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\\nf1 micro: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f9aeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_Tree_w_normalize(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "    DT_model = DecisionTreeClassifier()\n",
    "    DT_model.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    train_score = DT_model.score(X_scaled_train, y_train)\n",
    "    test_score = DT_model.score(X_scaled_test, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\\nf1 micro: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "930a046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_Tree_w_pca_normalize(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "    my_PCA = PCA()\n",
    "    my_PCA.fit(X_scaled_train)\n",
    "\n",
    "    X_train_PCA = my_PCA.transform(X_scaled_train)\n",
    "    X_test_PCA = my_PCA.transform(X_scaled_test)   \n",
    "    \n",
    "    DT_model = DecisionTreeClassifier()\n",
    "    DT_model.fit(X_train_PCA, y_train)\n",
    "    \n",
    "    train_score = DT_model.score(X_train_PCA, y_train)\n",
    "    test_score = DT_model.score(X_test_PCA, y_test)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "    y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "    report_initial = classification_report(y_test, y_pred)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    return print(f\"Train score: {train_score}\\nTest score: {test_score}\\n{report_initial}\\nf1 micro: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134a4c0",
   "metadata": {},
   "source": [
    "**Original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66da3e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.962641761174116\n",
      "Test score: 0.8861703683583712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     87544\n",
      "           1       0.25      0.17      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n",
      "f1 micro: 0.8861703683583712\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "D_Tree(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "017e65a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.962641761174116\n",
      "Test score: 0.8862226029543887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     87544\n",
      "           1       0.25      0.17      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n",
      "f1 micro: 0.8862226029543887\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "D_Tree_w_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37457807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Original dataset\n",
      "Train score: 0.962641761174116\n",
      "Test score: 0.8869329934602286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     87544\n",
      "           1       0.14      0.30      0.19      8178\n",
      "\n",
      "    accuracy                           0.79     95722\n",
      "   macro avg       0.54      0.57      0.54     95722\n",
      "weighted avg       0.86      0.79      0.82     95722\n",
      "\n",
      "f1 micro: 0.7874678757234491\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Original dataset\")\n",
    "D_Tree_w_pca_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084956c",
   "metadata": {},
   "source": [
    "The accuracy scores doesn't really change with normalization/dimention reduce. The scores of precision, recall, and f1 score became higher/lower on each when PCA was added, but the f1 micro score became very lower. Thefore, I'll optimize this dataset with no PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a1ee0",
   "metadata": {},
   "source": [
    "**Under Sampled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57362689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.7147468711476985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.19      0.74      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.73      0.56     95722\n",
      "weighted avg       0.90      0.71      0.78     95722\n",
      "\n",
      "f1 micro: 0.7147468711476985\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "D_Tree(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "549393ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.7147259773092914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.19      0.74      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.73      0.56     95722\n",
      "weighted avg       0.90      0.71      0.78     95722\n",
      "\n",
      "f1 micro: 0.7147259773092913\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "D_Tree_w_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26dc0ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Under sampled dataset\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.7163870374626523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.44      0.60     87544\n",
      "           1       0.08      0.49      0.13      8178\n",
      "\n",
      "    accuracy                           0.45     95722\n",
      "   macro avg       0.49      0.47      0.36     95722\n",
      "weighted avg       0.83      0.45      0.56     95722\n",
      "\n",
      "f1 micro: 0.4481832807505067\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Under sampled dataset\")\n",
    "D_Tree_w_pca_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e10c85",
   "metadata": {},
   "source": [
    "The test score increased when it's with PCA. However, all scores of precision, recall, and f1 became lower. Therefore, I'll optimize this dataset with no PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e0f5b",
   "metadata": {},
   "source": [
    "**Over Sampled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31e28994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.9753108782923725\n",
      "Test score: 0.837926495476484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     87544\n",
      "           1       0.19      0.27      0.22      8178\n",
      "\n",
      "    accuracy                           0.84     95722\n",
      "   macro avg       0.56      0.58      0.56     95722\n",
      "weighted avg       0.87      0.84      0.85     95722\n",
      "\n",
      "f1 micro: 0.837926495476484\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "D_Tree(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8c28e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.9753108782923725\n",
      "Test score: 0.8374668310315287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     87544\n",
      "           1       0.19      0.27      0.22      8178\n",
      "\n",
      "    accuracy                           0.84     95722\n",
      "   macro avg       0.56      0.58      0.56     95722\n",
      "weighted avg       0.87      0.84      0.85     95722\n",
      "\n",
      "f1 micro: 0.8374668310315287\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "D_Tree_w_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93370079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "Over sampled dataset\n",
      "Train score: 0.9753108782923725\n",
      "Test score: 0.8399740916403753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.84     87544\n",
      "           1       0.06      0.16      0.09      8178\n",
      "\n",
      "    accuracy                           0.73     95722\n",
      "   macro avg       0.49      0.47      0.47     95722\n",
      "weighted avg       0.84      0.73      0.78     95722\n",
      "\n",
      "f1 micro: 0.7329245105618353\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"Over sampled dataset\")\n",
    "D_Tree_w_pca_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596659c",
   "metadata": {},
   "source": [
    "The test score increased when it's with PCA. However, all scores of precision, recall, and f1 became lower. Therefore, I'll optimize this dataset with no PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40929b7",
   "metadata": {},
   "source": [
    "**SMOTE data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aaf94a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization and reducing dimention\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.753400472200748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n",
      "f1 micro: 0.753400472200748\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "D_Tree(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e0aba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only normalization\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.753400472200748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n",
      "f1 micro: 0.753400472200748\n"
     ]
    }
   ],
   "source": [
    "print(\"Only normalization\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "D_Tree_w_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15933485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization and reducing dimention\n",
      "\n",
      "SMOTE dataset\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.7534422598775621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.35      0.50     87544\n",
      "           1       0.08      0.63      0.15      8178\n",
      "\n",
      "    accuracy                           0.37     95722\n",
      "   macro avg       0.50      0.49      0.32     95722\n",
      "weighted avg       0.84      0.37      0.47     95722\n",
      "\n",
      "f1 micro: 0.37025971041139966\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalization and reducing dimention\\n\")\n",
    "\n",
    "print(\"SMOTE dataset\")\n",
    "D_Tree_w_pca_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fff46",
   "metadata": {},
   "source": [
    "The test scores doesn't really change with normalization/dimention reduce. However, all scores of precision, recall, and f1 became lower. Therefore, I'll optimize this dataset with no PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cd16b",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d643235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def DT_gridsearch(depth, split, leaf, X_train, y_train, X_test, y_test):\n",
    "    DT_param = {\n",
    "            'max_depth': depth,\n",
    "            'min_samples_split': split,\n",
    "            'min_samples_leaf': leaf,\n",
    "            'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "            'splitter': [\"best\", \"random\"],\n",
    "            'random_state': [42]\n",
    "        }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_scaled_train = scaler.transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    # Create Randomized Search\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), DT_param, cv=5, scoring=\"f1\")\n",
    "    # Fit the model\n",
    "    clf.fit(X_scaled_train, y_train)\n",
    "    \n",
    "    # prediction and evaluation\n",
    "    y_pred = clf.predict(X_scaled_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    # Result\n",
    "    best_clf = clf.best_estimator_\n",
    "    print('Hyperparameter :\\n', best_clf)\n",
    "    print('Train score:\\n', best_clf.score(X_scaled_train, y_train))\n",
    "    print('Test score:\\n', best_clf.score(X_scaled_test, y_test))\n",
    "    print(f\"Best F1 Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb95749",
   "metadata": {},
   "source": [
    "Each datasets have too many rows, so use sample rows from each datasets for GridSearch. Thefore, I'll take samples and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "102e486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take samples for GridSearch\n",
    "\n",
    "X_GS_original, X_rest_original, y_GS_original, y_rest_original = \\\n",
    "                train_test_split(X_train_original.loc[:, rfe_original.support_], y_train_original, train_size = 0.05, random_state=42)\n",
    "\n",
    "X_GS_under, X_rest_under, y_GS_under, y_rest_under = \\\n",
    "                train_test_split(X_train_under.loc[:, rfe_under.support_], y_train_under, train_size = 0.3, random_state=42)\n",
    "\n",
    "X_GS_over, X_rest_over, y_GS_over, y_rest_over = \\\n",
    "                train_test_split(X_train_over.loc[:, rfe_over.support_], y_train_over, train_size = 0.02, random_state=42)\n",
    "\n",
    "X_GS_smote, X_rest_smote, y_GS_smote, y_rest_smote = \\\n",
    "                train_test_split(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, train_size = 0.06, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10535db1",
   "metadata": {},
   "source": [
    "**Original data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a553ec0",
   "metadata": {},
   "source": [
    "train size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e220c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=27, min_samples_split=6,\n",
      "                       random_state=42)\n",
      "Train score:\n",
      " 0.9648070206859497\n",
      "Test score:\n",
      " 0.8777397045611249\n",
      "Best F1 Score: 0.22078700312936944\n",
      "CPU times: total: 32min 29s\n",
      "Wall time: 33min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 41, 2)\n",
    "split = range(2, 41, 2)\n",
    "leaf =  range(1, 41, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_GS_original, y_GS_original, \\\n",
    "        X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56f96",
   "metadata": {},
   "source": [
    "train size = full  \n",
    "The best hyperparameters are **max_depth=27, min_samples_split=6**. Therefore, I'll use the numbers close to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e3b65000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=29, random_state=42,\n",
      "                       splitter='random')\n",
      "Train score:\n",
      " 0.9622208989438149\n",
      "Test score:\n",
      " 0.8876015962892543\n",
      "Best F1 Score: 0.19894274439728984\n",
      "CPU times: total: 13min 18s\n",
      "Wall time: 13min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(21, 31, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(1, 11, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "        X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef25b0",
   "metadata": {},
   "source": [
    "The hyperparameter of max_depth was 29, but that is the highest range which I set, so the best max_depth might be higher. Therefore, I'll set the range of max_depth higher than above and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02a788a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=31, random_state=42,\n",
      "                       splitter='random')\n",
      "Train score:\n",
      " 0.9626014658541936\n",
      "Test score:\n",
      " 0.8876329370468649\n",
      "Best F1 Score: 0.19982145514060407\n",
      "CPU times: total: 16min 15s\n",
      "Wall time: 16min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(29, 41, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(1, 11, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "        X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a450bfee",
   "metadata": {},
   "source": [
    "The hyperparameter of max_depth is within the range, and the f1 score is improved. Therefore, I'll use those hyperparameters for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bdb6db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.9626014658541936\n",
      "Test score: 0.8876329370468649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     87544\n",
      "           1       0.26      0.16      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_train = scaler.transform(X_train_original.loc[:, rfe_original.support_])\n",
    "X_scaled_test = scaler.transform(X_test_original.loc[:, rfe_original.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=31, random_state=42, splitter='random')\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_original)\n",
    "    \n",
    "train_score_original = DT_model.score(X_scaled_train, y_train_original)\n",
    "test_score_original = DT_model.score(X_scaled_test, y_test_original)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_original = classification_report(y_test_original, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_original}\\nTest score: {test_score_original}\\n{report_initial_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01265ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.962641761174116\n",
      "Test score: 0.886327072146424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94     87544\n",
      "           1       0.25      0.17      0.20      8178\n",
      "\n",
      "    accuracy                           0.89     95722\n",
      "   macro avg       0.59      0.56      0.57     95722\n",
      "weighted avg       0.87      0.89      0.88     95722\n",
      "\n",
      "f1 micro: 0.886327072146424\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "D_Tree_w_normalize(X_train_original.loc[:, rfe_original.support_], y_train_original, \\\n",
    "            X_test_original.loc[:, rfe_original.support_], y_test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab54fd",
   "metadata": {},
   "source": [
    "The test score, recall for 0, and precision for 1 improved little bit. However, the recall for 1 became slightly lower than before optimization. Also, both recall scores for 1 of before/after optimization are lower than the other modeling methods/datasets. Therefore, this models cannot be a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507c0e7",
   "metadata": {},
   "source": [
    "**Under sampled data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9b0b6",
   "metadata": {},
   "source": [
    "train size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b8c61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_split=28,\n",
      "                       random_state=42, splitter='random')\n",
      "Train score:\n",
      " 0.751527850532565\n",
      "Test score:\n",
      " 0.7662292889826791\n",
      "Best F1 Score: 0.3414849474706454\n",
      "CPU times: total: 27min 42s\n",
      "Wall time: 28min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 41, 2)\n",
    "split = range(2, 41, 2)\n",
    "leaf =  range(1, 41, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_GS_under, y_GS_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb58645",
   "metadata": {},
   "source": [
    "train size =full  \n",
    "The best hyperparameters are **max_depth=7, min_samples_split=28**. Therefore, I'll use the numbers close to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c4f5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=9,\n",
      "                       min_samples_split=30, random_state=42,\n",
      "                       splitter='random')\n",
      "Train score:\n",
      " 0.7625320831805563\n",
      "Test score:\n",
      " 0.7185286558993753\n",
      "Best F1 Score: 0.32536244585221724\n",
      "CPU times: total: 57.6 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 11, 2)\n",
    "split = range(20, 31, 2)\n",
    "leaf =  range(1, 11, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c4927",
   "metadata": {},
   "source": [
    "All hyperparameters of max_depth, sample_split, and sample_leaf are on edge of the range. So all the best parameters might be higher. Therefore, I'll set the range of all the parameters higher than above and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b8ff7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=9,\n",
      "                       min_samples_split=30, random_state=42,\n",
      "                       splitter='random')\n",
      "Train score:\n",
      " 0.7625320831805563\n",
      "Test score:\n",
      " 0.7185286558993753\n",
      "Best F1 Score: 0.32536244585221724\n",
      "CPU times: total: 4min 3s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 16, 2)\n",
    "split = range(20, 35, 2)\n",
    "leaf =  range(1, 16, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6565ae7",
   "metadata": {},
   "source": [
    "Now, the all hyperparameters are within the range. Therefore, I'll use those hyperparameters for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df8a2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.7625320831805563\n",
      "Test score: 0.7185286558993753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.20      0.79      0.33      8178\n",
      "\n",
      "    accuracy                           0.72     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.72      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=9,\n",
    "                       min_samples_split=30, random_state=42, splitter='random')\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_under)\n",
    "    \n",
    "train_score_under = DT_model.score(X_scaled_train, y_train_under)\n",
    "test_score_under = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_under = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_under}\\nTest score: {test_score_under}\\n{report_initial_under}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "989b03e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.8012152323084176\n",
      "Test score: 0.7148304465013268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.19      0.74      0.31      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.58      0.73      0.56     95722\n",
      "weighted avg       0.90      0.71      0.78     95722\n",
      "\n",
      "f1 micro: 0.7148304465013269\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "D_Tree_w_normalize(X_train_under.loc[:, rfe_under.support_], y_train_under, \\\n",
    "        X_test_sampled.loc[:, rfe_under.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f0e50",
   "metadata": {},
   "source": [
    "The test score, precision for 1, and recall for 1 improved by optimizing hyperparameters. Also, the recall score for 1 is as high as the other chosen machine learning models. Therefore, I'll compare this model to other datasets models with dicision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13eeda",
   "metadata": {},
   "source": [
    "**Over sampled data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179f6a1",
   "metadata": {},
   "source": [
    "train size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f8defd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=27,\n",
      "                       random_state=42, splitter='random')\n",
      "Train score:\n",
      " 0.7510403916768665\n",
      "Test score:\n",
      " 0.6977392866843568\n",
      "Best F1 Score: 0.3131632047477745\n",
      "CPU times: total: 35min 26s\n",
      "Wall time: 37min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 41, 2)\n",
    "split = range(2, 41, 2)\n",
    "leaf =  range(1, 41, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_GS_over, y_GS_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b544d8a",
   "metadata": {},
   "source": [
    "train size = full  \n",
    "The best hyperparameters are **max_depth=7, min_samples_leaf=27**. Therefore, I'll use the numbers close to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db4506ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(max_depth=9, min_samples_leaf=23, random_state=42)\n",
      "Train score:\n",
      " 0.7661509840399491\n",
      "Test score:\n",
      " 0.7124903365997367\n",
      "Best F1 Score: 0.32142416845427424\n",
      "CPU times: total: 14min 13s\n",
      "Wall time: 14min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 11, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(21, 31, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c40b11",
   "metadata": {},
   "source": [
    "The hyperparameter of max_depth was 9, but that is the highest range which I set, so the best max_depth might be higher. Therefore, I'll set the range of max_depth higher than above and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "17da0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(max_depth=19, min_samples_leaf=21, random_state=42)\n",
      "Train score:\n",
      " 0.8293522960932145\n",
      "Test score:\n",
      " 0.7494933244186289\n",
      "Best F1 Score: 0.3006387260477732\n",
      "CPU times: total: 36min 1s\n",
      "Wall time: 37min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(7, 20, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(21, 31, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f8300",
   "metadata": {},
   "source": [
    "The hyperparameters of max_depth and min_samples_leaf are on edge of the range. So I'll set the range of those parameters higher/lower than above and try GridSearch again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a121b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(max_depth=25, min_samples_leaf=15, random_state=42)\n",
      "Train score:\n",
      " 0.8592578086752178\n",
      "Test score:\n",
      " 0.7646100165061324\n",
      "Best F1 Score: 0.2905094779268216\n",
      "CPU times: total: 1h 26min 55s\n",
      "Wall time: 1h 31min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(7, 26, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(15, 31, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad0899",
   "metadata": {},
   "source": [
    "The hyperparameters of max_depth and min_samples_leaf are on edge of the range again. So I'll set the range of those parameters higher/lower than above and try GridSearch again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d88aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=31, min_samples_leaf=9,\n",
      "                       random_state=42)\n",
      "Train score:\n",
      " 0.8983574855576226\n",
      "Test score:\n",
      " 0.7821712876872611\n",
      "Best F1 Score: 0.28280535204485263\n",
      "CPU times: total: 41min 56s\n",
      "Wall time: 43min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(21, 32, 2)\n",
    "split = range(2, 11, 2)\n",
    "leaf =  range(9, 19, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b4944",
   "metadata": {},
   "source": [
    "The test score is getting better on each gridsearch. However, the f1 score is getting lower. Therefore, I'll check the models with (max_depth=9, min_samples_leaf=23, random_state=42) which has the highest f1 score and (criterion='entropy', max_depth=31, min_samples_leaf=9, random_state=42) which has the highest test score so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4105f05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7661509840399491\n",
      "Test score: 0.7124903365997367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.20      0.80      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Model 1 ##\n",
    "# highest f1 score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(max_depth=9, min_samples_leaf=23, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_over)\n",
    "    \n",
    "train_score_over = DT_model.score(X_scaled_train, y_train_over)\n",
    "test_score_over = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_over = classification_report(y_test_sampled, y_pred)\n",
    "    \n",
    "print(f\"Train score: {train_score_over}\\nTest score: {test_score_over}\\n{report_initial_over}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2dbd0de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8983574855576226\n",
      "Test score: 0.7821712876872611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87     87544\n",
      "           1       0.20      0.50      0.28      8178\n",
      "\n",
      "    accuracy                           0.78     95722\n",
      "   macro avg       0.57      0.66      0.58     95722\n",
      "weighted avg       0.88      0.78      0.82     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Model 2 ##\n",
    "# highest test score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=31, min_samples_leaf=9, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_over)\n",
    "    \n",
    "train_score_over = DT_model.score(X_scaled_train, y_train_over)\n",
    "test_score_over = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_over = classification_report(y_test_sampled, y_pred)\n",
    "    \n",
    "print(f\"Train score: {train_score_over}\\nTest score: {test_score_over}\\n{report_initial_over}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec280122",
   "metadata": {},
   "source": [
    "Model 2 has much higher test score. However, the recall score for 1 is only 0.5, which means only 50% of person who have a heart disease are predicted correctly. On the other hand, Model 1 has 0.8 of recall score for 1. Therefore, I'll evaluate Model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2f0c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.7661509840399491\n",
      "Test score: 0.7124903365997367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.20      0.80      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(max_depth=9, min_samples_leaf=23, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_over)\n",
    "    \n",
    "train_score_over = DT_model.score(X_scaled_train, y_train_over)\n",
    "test_score_over = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_over = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_over}\\nTest score: {test_score_over}\\n{report_initial_over}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "553caf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.9753108782923725\n",
      "Test score: 0.8375086187083429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     87544\n",
      "           1       0.19      0.27      0.22      8178\n",
      "\n",
      "    accuracy                           0.84     95722\n",
      "   macro avg       0.56      0.58      0.56     95722\n",
      "weighted avg       0.87      0.84      0.85     95722\n",
      "\n",
      "f1 micro: 0.8375086187083429\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "D_Tree_w_normalize(X_train_over.loc[:, rfe_over.support_], y_train_over, \\\n",
    "        X_test_sampled.loc[:, rfe_over.support_], y_test_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48497cd",
   "metadata": {},
   "source": [
    "The accuracy scores became lower than the model before optimization. However, the recall score for 1 improved a lot. Therefore, I'll compare this model to other dataset models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadb9e8",
   "metadata": {},
   "source": [
    "**SMOTE data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a960b",
   "metadata": {},
   "source": [
    "train size = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ab7351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=15, min_samples_leaf=3,\n",
      "                       min_samples_split=22, random_state=42,\n",
      "                       splitter='random')\n",
      "Train score:\n",
      " 0.8012728978825834\n",
      "Test score:\n",
      " 0.7476337728004011\n",
      "Best F1 Score: 0.3040133682906451\n",
      "CPU times: total: 37min 41s\n",
      "Wall time: 39min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(1, 41, 2)\n",
    "split = range(2, 41, 2)\n",
    "leaf =  range(1, 41, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_GS_smote, y_GS_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34725461",
   "metadata": {},
   "source": [
    "train size = full  \n",
    "The best hyperparameters are **max_depth=15, min_samples_leaf=3,\n",
    "                       min_samples_split=22**. Therefore, I'll use the numbers close to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35717093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=13, min_samples_split=18,\n",
      "                       random_state=42)\n",
      "Train score:\n",
      " 0.8058528346225399\n",
      "Test score:\n",
      " 0.753578069827208\n",
      "Best F1 Score: 0.3065616180620884\n",
      "CPU times: total: 15min 52s\n",
      "Wall time: 16min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(11, 21, 2)\n",
    "split = range(18, 29, 2)\n",
    "leaf =  range(1, 11, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66140221",
   "metadata": {},
   "source": [
    "The hyperparameter of min_samples_split is on edge of the range. So the best parameter of min_samples_split might be lower. Therefore, I'll set the range of the parameter lower than above and do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c0424b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter :\n",
      " DecisionTreeClassifier(max_depth=15, min_samples_leaf=3, min_samples_split=16,\n",
      "                       random_state=42, splitter='random')\n",
      "Train score:\n",
      " 0.805302065994321\n",
      "Test score:\n",
      " 0.7533586845239338\n",
      "Best F1 Score: 0.30596466472646033\n",
      "CPU times: total: 20min 27s\n",
      "Wall time: 20min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth = range(11, 21, 2)\n",
    "split = range(14, 29, 2)\n",
    "leaf =  range(1, 11, 2)\n",
    "\n",
    "DT_gridsearch(depth, split, leaf, X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ad8a7",
   "metadata": {},
   "source": [
    "Now, all the hyperparameters are within the range. However, the test score and f1 score became lower after setting the range of min_samples_split wider. Therefore, I'll use the hyperparameters one before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ef5b595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization\n",
      "\n",
      "Train score: 0.8058528346225399\n",
      "Test score: 0.753578069827208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=13, min_samples_split=18, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_smote)\n",
    "    \n",
    "train_score_smote = DT_model.score(X_scaled_train, y_train_smote)\n",
    "test_score_smote = DT_model.score(X_scaled_test, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_smote = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"After optimization\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_smote}\\nTest score: {test_score_smote}\\n{report_initial_smote}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0927f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization\n",
      "\n",
      "Train score: 0.8059678840693234\n",
      "Test score: 0.753400472200748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n",
      "f1 micro: 0.753400472200748\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization\\n\")\n",
    "\n",
    "D_Tree_w_normalize(X_train_smote.loc[:, rfe_smote.support_], y_train_smote, \\\n",
    "        X_test_smote.loc[:, rfe_smote.support_], y_test_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a97eb6",
   "metadata": {},
   "source": [
    "The test score improved slightly, but other scores didn't change. However, this model got better test score than the other models. Therefore, I'll compare this model to others at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe352d",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4e4a98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under Sampled data\n",
      "\n",
      "Train score: 0.7625320831805563\n",
      "Test score: 0.7185286558993753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     87544\n",
      "           1       0.20      0.79      0.33      8178\n",
      "\n",
      "    accuracy                           0.72     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.72      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Under sampled data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_train = scaler.transform(X_train_under.loc[:, rfe_under.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_under.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=9,\n",
    "                       min_samples_split=30, random_state=42, splitter='random')\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_under)\n",
    "    \n",
    "train_score_under = DT_model.score(X_scaled_train, y_train_under)\n",
    "test_score_under = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_under = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"Under Sampled data\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_under}\\nTest score: {test_score_under}\\n{report_initial_under}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2530a00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over Sampled data\n",
      "\n",
      "Train score: 0.7661509840399491\n",
      "Test score: 0.7124903365997367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.70      0.82     87544\n",
      "           1       0.20      0.80      0.32      8178\n",
      "\n",
      "    accuracy                           0.71     95722\n",
      "   macro avg       0.59      0.75      0.57     95722\n",
      "weighted avg       0.91      0.71      0.78     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Over sampled data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_train = scaler.transform(X_train_over.loc[:, rfe_over.support_])\n",
    "X_scaled_test = scaler.transform(X_test_sampled.loc[:, rfe_over.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(max_depth=9, min_samples_leaf=23, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_over)\n",
    "    \n",
    "train_score_over = DT_model.score(X_scaled_train, y_train_over)\n",
    "test_score_over = DT_model.score(X_scaled_test, y_test_sampled)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_over = classification_report(y_test_sampled, y_pred)\n",
    "\n",
    "print(\"Over Sampled data\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_over}\\nTest score: {test_score_over}\\n{report_initial_over}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "11d63f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE data\n",
      "\n",
      "Train score: 0.8058528346225399\n",
      "Test score: 0.753578069827208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85     87544\n",
      "           1       0.20      0.64      0.31      8178\n",
      "\n",
      "    accuracy                           0.75     95722\n",
      "   macro avg       0.58      0.70      0.58     95722\n",
      "weighted avg       0.89      0.75      0.80     95722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SMOTE data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_train = scaler.transform(X_train_smote.loc[:, rfe_smote.support_])\n",
    "X_scaled_test = scaler.transform(X_test_smote.loc[:, rfe_smote.support_])\n",
    "    \n",
    "DT_model = DecisionTreeClassifier(criterion='entropy', max_depth=13, min_samples_split=18, random_state=42)\n",
    "\n",
    "DT_model.fit(X_scaled_train, y_train_smote)\n",
    "    \n",
    "train_score_smote = DT_model.score(X_scaled_train, y_train_smote)\n",
    "test_score_smote = DT_model.score(X_scaled_test, y_test_smote)\n",
    "    \n",
    "    # Evaluation(precision & Recall)\n",
    "y_pred = DT_model.predict(X_scaled_test)\n",
    "\n",
    "report_initial_smote = classification_report(y_test_smote, y_pred)\n",
    "\n",
    "print(\"SMOTE data\\n\")\n",
    "    \n",
    "print(f\"Train score: {train_score_smote}\\nTest score: {test_score_smote}\\n{report_initial_smote}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715db66b",
   "metadata": {},
   "source": [
    "SMOTE data model has the best test score. However, Over sampled data has the highest recall score for 1. I would like to pridict person who has heart disease more than pridicting person who doesn't have heart disease, so I'll choose Over sampled data model from Dicision Tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc9e41",
   "metadata": {},
   "source": [
    "**From Logistic Regression: Over Sampled dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8a27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
